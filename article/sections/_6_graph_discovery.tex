\section{Causal Discovery}
\label{sec:causal-discovery}

% How is causal discovery related to testing causal graphs?
In the previous section, we detailed one method for testing the marginal and conditional independence assumptions of one's causal graph.
As presented, this strategy requires one to first have a causal graph.
Indeed, this requirement is why Section \ref{sec:graph-construction} provides instruction on how to construct an initial causal graph using expert opinion.

The unstated presumption is that one will test one's working causal graph, and if any of tests fail, one will then revise the graph until all assumptions appear plausible.
Essentially, one proceeds in a loop of postulating, testing, and editing one's causal graph until it is not blatantly contradicted by one's data.
If this sounds tedious, one can consider making one's computer work for you.
Specifically, by exchanging the human-in-the-loop for a purely algorithmic endeavor, one arrives at the practice of  causal discovery: inferring one's causal graph from one's data.

This section will describe why causal discovery is important, provide a brief overview of the main concepts in causal discover, and show the results of using causal discovery algorithms on the dataset described in Section \ref{sec:graph-importance}.

\subsection{Why use causal discovery?}

% Why is causal discovery important?
% Promotes robustness and understanding of results
% Inspires creation and editing of expert-opinion graph
% Aids characterization of posterior uncertainty
As a topic of study, causal discovery is important for numerous reasons.
Three of these reasons are the following.
First, causal discovery promotes robustness and understanding of our causal effect estimates.
By comparing against our causal effect estimates when using a data-driven causal graph, we can begin to understand how our prior beliefs affect our estimates.
Secondly, causal discovery helps inspire creation and editing of expert-opinion graphs.
Indeed, it's typically easier to edit than to create from scratch.
Graphs found via causal discovery can spark ideas for one's own graph if they feature different causal relations than are present in one's own graph, and they provide a starting point for graph revision.
Thirdly, causal discovery algorithms can aid characterization of posterior uncertainty in one's causal graph and causal effect estimates.
Each causal graph discovered from one's data represents an alternative way of understanding the world, and we can quantify the probability of each of these causal models representing our data generating process.

% Why does causal discovery help robustness and model understanding?
Let's begin with robustness.
Here, one way of reducing the probability of incorrect inferences is to give oneself multiple chances to be correct.
In particular, the Section \ref{sec:graph-testing} tested, expert-opinion based graph was never meant to be the stopping point in one's exploration of possible causal relationships.
Instead, we advocate using multiple graphs to help us understand our causal effect estimates.

Specifically, consider that a causal graph is equivalent to a square matrix with one row for each variable, and binary entries that denote whether the variable for the row causes the variable on the column \citep[p. 3]{glymour_2019_review}.
A prior that expresses maximum ignorance over the graphs would be a prior where each matrix entry followed its own Bernoulli distribution with $p=0.5$.
Conversely, a prior expressing maximum certainty over the graph could be a prior with 100\% certainty that our expert-opinion graph is the true causal graph.
These two extremes represent reference priors that we can use in sensitivity analyses.
By observing the distribution of causal effect estimates under each prior, we can reflect the uncertainty from not knowing the ``true'' causal graph, and we can begin to understand the ways that our estimates are sensitive our prior beliefs.

% How does causal discovery help inspire our creation and editing of an expert-opinion causal graph?
Beyond increasing our understanding of our estimates, causal discovery algorithms can help us create causal graphs based on expert-opinion.
In particular, criticizing causal graphs is easy.
As noted by \citet{pearl_1995_causal}, ``every pair of nodes in the graph waves its own warning flag in front of the modeller's eyes: 'Have you neglected an arrow or a dashed arc?''
Additionally, the presence of directed causal relations is vividly placed before one's eyes for immediate criticism (e.g., is $X \rightarrow Y$ plausible?).
And conversely, we may learn from causal links (i.e. arrows) that are present in the graphs output from our causal discovery algorithm that we initially overlooked.
By contrasting and criticizing alternative graphs, we clarify the strengths and deficiencies of our own point of view.
Once we've identified elements that we think should or should not be present in a causal graph for our dataset, we can amend our hand-crafted graph to meet these requirements.

% How does causal discovery help characterize posterior uncertainty about the  true causal graph?
% Weighted bootstrap posterior
Lastly, causal discovery can help us characterize our posterior uncertainty about the data-generating causal graph.
They enable approximation of the posterior distribution over causal graphs, in at least two ways.
One approach is to use a weighted likelihood bootstrap approximation \citep{newton_1994_approximate} to the posterior distribution over graphs.
In this approach, one would first sample a vector of weights for the likelihood terms.
Then, one would use those weights in one's causal discovery algorithm to produce a single `sample' from the posterior approximation.

%Randomize-then-optimize.
Alternatively, we could use yet another randomize-then-optimize \citep{bardsley_2014_randomize, orabona_2014_measure} approach to sampling from an approximate posterior distribution.
Here, one would sample from a prior on entries of the matrix representation of a causal graph.
Semantically, we sample constraints such as ``$X \rightarrow Y$ (MUST | MUST NOT) be in the causal graph''.
We ``sample'' from the approximate posterior by running the causal discovery algorithm on the original dataset, with the inclusion of these randomly generated constraints.
And, of course, we can consider hybrids of these two posterior approximation schemes.

With these posterior approximation methods, we can generate causal graphs for all the purposes mentioned above:
\begin{itemize}
   \item for criticism and inspiration,
   \item for distributional analyses of one's causal effect estimates conditional on each sampled graph, and
   \item for distributional analyses of the causal graphs themselves.
   \newline
   I.e., how certain are we of any one causal graph?
\end{itemize}

\subsection{Overview of causal discovery algorithms}

% Pointers to thorough review papers
The following subsection presents a non-exhaustive overview of causal discovery algorithms.
For conciseness, an exhaustive review of causal discovery algorithms is out of the scope of the article.
Crucially, we rely heavily on review papers such as \citet{glymour_2019_review} and \citet{spirtes_2016_causal} to fill in our gaps.


% Types of causal discovery algorithms
Overall, there are three classes of causal discovery algorithms.
One class attempts to directly infer the marginal and conditional independences in one's causal system.
Considering the discussion of independence testing in Section \ref{sec:graph-testing}, this class of algorithms is perhaps best understood as repeated and systematic independence tests.
These causal discovery algorithms are constraint-based algorithms, because the observed independencies represent constraints that define the space of plausible causal graphs for the dataset.
Common constraint-based algorithms include the Peter-Clarke (PC) algorithm and the Fast Causal Inference (FCI) algorithm \citep{glymour_2001_causation}.
The PC algorithm assumes no unobserved confounding variables, whereas the FCI allows for (and sometimes infers) the presence of such unobserved confounders.

% DESCRIBE SCORE BASED DISCOVERY ALGORITHMS
The second class of algorithm proceeds sequentially by variable, trying to estimate the dependencies between each variable and every other available variable.
These algorithms are score-based algorithms.
They typically compute a score for each possible dependency (i.e. $X \rightarrow Y$ and $X \leftarrow Y$), and then they use these scores to select a single graph.
Common score-based algorithms include the Greedy Equivalence Search (GES) algorithm \citep{chickering_2002_optimal}.

% DESCRIBE FCM ALGORITHMS
%Lastly, the third class of algorithms relies on hypothesized Functional Causal Models (FCM) \citep{} for each of the variables in one's system.
%Because these algorithms analyze directed relationships, as opposed to only analyzing independencies, they provide more information than the constraint-based algorithms.
%In particular, FCM-based methods permit inferences in the two-variable case, allowing one to infer whether $X \rightarrow Y$ or $Y \rightarrow X$.
%Of course, such strength does not come for free.

% What questions can be addressed via these discovery algorithms
% $X \rightarrow Y$ or $X \leftarrow Y$
% Full graph inference (with and without allowance-for / detection-of latent confounders)
% Discovery of equivalence classes


\subsection{An application of causal discovery}
