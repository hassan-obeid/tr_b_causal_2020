{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. At a “high” level, how will the project deliver each of the needed requirements?\n",
    "- **Try to think in terms of some manageable (e.g. 10-20) steps**\n",
    "- **List needed intermediate products (e.g. pseudo-code, unit tests, etc.)**\n",
    "- **Try to be concise but comprehensive?**\n",
    "\n",
    "The project is split into three main tasks:\n",
    "\n",
    "1. The first task is focused on a selection-on-observables problem:\n",
    "\n",
    "For a causal graph with independent covariates:\n",
    " 1. Ingest data\n",
    " 2. Manipulate data as needed, the output of this step will be a cleaned dataset\n",
    " 3. Specify a choice model based on the data at hand, the specification should follow required conventions by third party dependencies\n",
    " 4. The cleaned dataset will be used in a function that estimated the distributions for variables of interest, this function will produce a parameter dictionary containing the type of variables, the best fitted distribution, and that distribution parameters.\n",
    " 5. The resulting parameter dictionary from the previous step will be used to simulate needed data\n",
    " 6. Based on observed availability of allternatives, a function will use the cleaned dataset to simulate an availability matrix for alternatives for the simulated dataset\n",
    " 7. The specified model from step 3 will be used to simulate choices for the simulated dataset.\n",
    " 8. The dataset will be used to estimate a choice model and recover the necessary parameters. These parameters can be stored in a dictionary.\n",
    " 9. Steps 5-8 will be repeated for N times (say 100) and the parameters from each iteration will be stored in a dictionary entry.\n",
    " 10. These paramaters will be stored in a dictionary that will be used in a function to plot the original parameters used to simulate the choices (from step 3) along with any recovered parameters from step 9.\n",
    " 11. One variable will be perturbed to simulate a potential external intervention. In this scenario, no other variables will be changes since all covariates are independent.\n",
    " 12. Causal effects will be estimated using the models estimated in step 3 and 9.\n",
    " 13. Plots will be produced to show the distribution of \"naive\" and \"true\" causal effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a realistic causal graph with confounding:\n",
    " 1. Ingest data\n",
    " 2. Manipulate data as needed, the output of this step will be a cleaned dataset\n",
    " 3. Specify a choice model based on the data at hand, the specification should follow required conventions by third party dependencies\n",
    " 4. Specify the realistic causal graph with desired confounding structures. The causal graph will be saved as a causalgraphicalmodels object and can be saved as .png file\n",
    " 5. The cleaned dataset will be used in a function that estimated the distributions for variables of interest that are nodes without any parents in the causal graph, this function will produce a parameter dictionary containing the type of variables, the best fitted distribution, and that distribution parameters.\n",
    " 6. The cleaned dataset from step 2 will be used to estimate relationships between nodes in the specified causal graph from step 4.\n",
    " 7. The obtained distributions from step 5 will be used to simulate data for nodes without parents in the specified causal graph.\n",
    " 8. Data from step 7, alongside with estimated relationships from step 6 will be used to estimate data for the remaining nodes in the causal graph (with the exception of the utility node)\n",
    " 9. Based on observed availability of allternatives, a function will use the cleaned dataset to simulate an availability matrix for alternatives for the simulated dataset\n",
    " 10. The specified model from step 3 will be used to simulate choices for the simulated dataset.\n",
    " 11. The dataset will be used to estimate a choice model and recover the necessary parameters. These parameters can be stored in a dictionary.\n",
    " 12. Steps 7-11 will be repeated for N times (say 100) and the parameters from each iteration will be stored in a dictionary entry.\n",
    " 13. These paramaters will be stored in a dictionary that will be used in a function to plot the original parameters used to simulate the choices (from step 3) along with any recovered parameters from step 9.\n",
    " 14. One variable will be perturbed to simulate a potential external intervention. In this scenario, descendant children nodes of the perturbed node will also be perturbed following the estimated relationships from step 8.\n",
    " 15. Causal effects will be estimated using the models estimated in step 3 and 121.\n",
    " 16. Plots will be produced to show the distribution of \"estimated\" and \"true\" causal effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Description of major components of the system and their relations:\n",
    "### 2.1 What should each component do?\n",
    "1. The goal of showing the need of considering treatment assignment mechanism when estimating causal effects requires show an application of the steps outlined in Brathwaite and Walker (2018a) to a simulated dataset from Brathwaite and Walker (2018b). This application will consitute of the following classes/functions:\n",
    "   - Simulation functions will generate data based on any assumed causal graph (either with independent covariates or any relation between nodes)\n",
    "   - Function to fit regression between different nodes from a specified causal graph\n",
    "   - Function (based on pylogit) to estimate choice models based on desired specifications and specific data\n",
    "   - Function to compute causal effects due to perturbation in data\n",
    "Choice model estimation will try to recover the true parameters of the specified model\n",
    "   - Function to plot the distribution of estimated choice model paramaters\n",
    "   - Function to plot the distribution of causal effects (naive, true, and estimated)\n",
    "\n",
    "### 2.2 What is the interface between each component and each other component?\n",
    "Each component(classes) will be written to be as independent as possible from other components. Functions within classes\n",
    "will depend on each other.\n",
    "However, we will write functions that test the output of each of our functions to make sure we get the expected output.\n",
    "In general, the interface between each of the project components will be some sort of data: dictionaries storing distribution parameters,\n",
    "simulated data, estimated model parameters and causal effects, causal graphs, arrays of statistics about estimated model parameters or estimated causal effects, distribution statistics. **this list is not\n",
    "comprehsive yet** Answer to question 7.6 provides a checklist of data characteristics that will be checked.\n",
    "\n",
    "### 2.3 How do components use each other (if they do?), and which ones are allowed to use which other components?\n",
    "Outputs of simulation classes/functions will be used in estimation classes/functions. \n",
    "Outputs of estimation classes/functions will be used in plotting functions.\n",
    "\n",
    "## 3. Description of needed development / computational environment:\n",
    "### 3.1  Where will development take place (virtual environments? One’s laptop, etc.)?\n",
    "\n",
    "- There are two alternatives:\n",
    "  - **Virtual Machine**: Install JupyterHub on cloud server with multiple users and the same environment for each user. Collaborate directly on the Jupyter Notebooks and convert them to Jupytext .py files for easier code review and version control.\n",
    "  - **Personal laptop**: work locally on personal laptop and push changes as progress is made to the right folder in the github repository.\n",
    "\n",
    "### 3.2  How will one reliably construct the needed computational environment?\n",
    "\n",
    "- There are two Alternatives:\n",
    "  - If using **Virtual Machine**: The created JupyterHub server will have all the dependencies installed and available to all users on the server. The server administrator will be responsible for installing necessary environment from a .yml file.\n",
    "  \n",
    "  - If using **personal laptop**: \n",
    "      * Create a conda virtual environment with all the necessary packages for the project, and push it to the github repository as a .yml file in order for it to be duplicated by other members and end users, **OR**\n",
    "      * Create a Docker image of the computational environment to be used by all team members.\n",
    "\n",
    "### 3.3  How will one test that the computational environment is correctly created?\n",
    "\n",
    "- Shell commands in either situation will be used to check that the correct environment was created/installed.\n",
    "- Write class/function to make sure each of the needed packages and right python version is installed.\n",
    "\n",
    "## 4. Description of major classes to be used (relates to major components above):\n",
    "<!--- **Class responsibilities**\n",
    "- **Interactions between classes**\n",
    "- **Class hierarchies / state transitions / object persistence**\n",
    "- **Organization of classes into subsystems (if necessary / planned)**\n",
    "- **Why does each class have “jurisdiction” over the parts of the system that it does?** -->\n",
    "\n",
    "The classes are to be used in the simulation work are as follows:\n",
    " -  Class that contains functions to simulate data based on best fit distributions\n",
    " -  Class that contains functions to simulate data based on assumed causal graph\n",
    " -  Class to estimate the choice model based on specified utility equations and retrieve model statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Description of the minimally viable product (if any):\n",
    "- **Note the portions of the architecture responsible for producing the minimally viable product.**\n",
    "\n",
    " - For objective 1, a minimally viable product is a notebook that takes data from outside sources and imports scripts including classes\n",
    " from question 4, calls on the functions in each of the classes to simulate data, estimate models, estimate causal effects due to an intervention, and plot distribution of obtained causal effects.\n",
    "\n",
    "## 6. Description of algorithms:\n",
    "### 6.1  What, if any, computational algorithms are being implemented as part of this project instead of relying upon external implementations?\n",
    "Hassan to fill in based on the deconfounder work.\n",
    "\n",
    "### 6.2 What purpose(s) do those algorithms serve?\n",
    "See above\n",
    "\n",
    "### 6.3 Are each of these algorithms fully understood by someone on the project team?\n",
    "See above\n",
    "\n",
    "### 6.4  What are alternative algorithms that could have served the purposes of the algorithms we are implementing?\n",
    "See above\n",
    "\n",
    "### 6.5 Why are we using the particular algorithms we’ve chosen instead of others? \n",
    "See above\n",
    "\n",
    "### 6.6 Why do we believe the algorithms can be implemented?\n",
    "See above\n",
    "\n",
    "### 6.7 Do we have any concerns with regard to algorithmic efficiency?\n",
    "See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Description of data usage in the system:\n",
    "### 7.1 How will data be ingested / accessed?\n",
    "Data will be ingested using pandas from either an online path to the dataset or from a local path on the user's machine\n",
    "\n",
    "### 7.2 How will data be validated?\n",
    "Data will be validating by reestimating the models from the Assymetric paper by Brathwaite and Walker.\n",
    "\n",
    "### 7.3 How will data be organized?\n",
    "Data will be organized in tabular format (.csv)\n",
    "\n",
    "### 7.4 How will data be transformed?\n",
    "Data will be transformed using methods available within Pandas\n",
    "\n",
    "### 7.5 How will created data be output and stored?\n",
    "Causal graphs will be output to .png files and pushed to the repo\n",
    "\n",
    "Summaries of model estimate will be saved as markdown tables\n",
    "\n",
    "Plots of results will be saved as .png files and pushed to the repo and included in the final presentation\n",
    "\n",
    "Previously estimated models will be stored in a dictionary that can be pickled and loaded later.\n",
    "### 7.6 How will created data be validated?\n",
    "The simulated data will be validated as follows:\n",
    "- Ensure we have all the columns we expect\n",
    "- Ensure all columns have the correct tyoes\n",
    "- Ensure all numeric columns have the expected ranges\n",
    "- Ensure the numeric columns having the means and variances within expected ranges\n",
    "- Ensure we have the correct number of observations\n",
    "\n",
    "This will be achieved by writing a function running all assertions needed.\n",
    "\n",
    "\n",
    "### 7.7 How does all of the above differ online vs offline? (e.g. we may throw a critical error offline to prevent training with bad data but only log a warning online to note that the data in a request was unexpected.)\n",
    "N/A\n",
    "\n",
    "### 7.8 How will the flow / manipulation of data be controlled (and recorded / version-controlled) and made reproducible? E.g. data ingestion and manipulation to create training / testing sets.\n",
    "- **Flyte?**\n",
    "- **Make?**\n",
    "- **Other?**  \n",
    "Developing a project workflow file that shows how all specified requirements of each workflow\n",
    "step are met. \n",
    "\n",
    "## 8. Description of experimentation protocols (if relevant):\n",
    "**If experiments need to be run (e.g. hyper-parameter tuning, model-selection, A/B tests, etc.):**\n",
    "### 8.1 How will experiments be launched?\n",
    "We can launch the experiment from a jupyter notebook, and **hopefully** from the command line.\n",
    "\n",
    "### 8.2 How will experiment reproducibility be ensured?\n",
    "Simulated data, as well as any experiment output will be store either in csv/json/pickle file\n",
    "based on the nature of the object (dataset, model, etc..) and will be loaded into a notebook.\n",
    "A third party library called `sacred` can be used https://sacred.readthedocs.io/en/stable/\n",
    "Setting seed parameters in our functions will also be helpful in reproducing the results of our experiments.\n",
    "\n",
    "### 8.3 How will experiment meta-data (e.g. launch configurations) be stored?\n",
    "The meta-data for the experiment could be stored in a requirements.txt, the source code,\n",
    "and parameters stored in a .json/pickle/csv file. the sacred library has a `run` object\n",
    "that stores all experiment info and configuration.\n",
    "\n",
    "### 8.4 How will experiment-created data (e.g. results) be stored?\n",
    "The experiment-created data will be stored in json/pickle/csv files.\n",
    "\n",
    "### 8.5 How will experiment-created data be analyzed?\n",
    "Experiment metrics will be analyzed to find statistics about means and variances of parameters\n",
    "to make sure they fall within the expected ranges.\n",
    "\n",
    "### 8.6 How will experiment analyses be prepared for public reporting? \n",
    "Experiment analyses will be stored in .json/csv files and used to create plots summarizing\n",
    "results of the experiments.\n",
    "\n",
    "## 9. Description of user-interface:\n",
    "### 9.1 How will users (including myself) interact with the system that is built?\n",
    "- **Will there be a command line interface?**\n",
    "- **Will users be editing configuration files, and if so, where will they be stored?**\n",
    "- **Will there be ability to replay the DAG representing one’s data analysis?**\n",
    "\n",
    "Users will use a jupyter notebook to interact with the system. The `papermill` library\n",
    "will be used to parametrize a notebook. Parameters of the notebook could also be saved\n",
    "in a .json file that is loaded into the notebook. For experiments, the `sacred` library\n",
    "will help in storing experiment paramters.\n",
    "\n",
    "### 9.2 How will ease of changes be ensured (e.g. changing a given hyperparameter value in the source code of a model)?\n",
    "Each hyperparameter that needs to be tuned will be included in the parameter definition of a function. Users will be\n",
    "able to change these parameters directly from the notebook running the functions of interest. These parameters will be set as initial global notebook variables than can be easily changed by the users.\n",
    "\n",
    "### 9.3 Is the user-interface self-contained so that other parts of the system are insulated from changes in the user-interface?\n",
    "Yes. Users will not be able to make any changes to the source code by interacting with the notebook.\n",
    "\n",
    "## 10. Description of resource-management:\n",
    "### 10.1 How will the system cope with large amounts of data during model training?\n",
    "The system will not have to deal with large amounts of data that personal laptops will not be able to handle.\n",
    "\n",
    "### 10.2 How much memory and time will it take the system to execute?\n",
    "- **Offline / online prediction**\n",
    "- **Model training**\n",
    "Any personal laptop should be able to execute the system. We don't envision the need for large memory requirements.\n",
    "It is unknown exactly how long it will take the system to run, but the objective is to have each sub-system take as little time as possible.\n",
    "As of now, the notebook representing the deliverable for objective 1 of the project runs in 20 minutes for 400 simulations. This time can be further reduced by refactoring the current functions responsible for achieving the objective of the notebook.\n",
    "\n",
    "### 10.3 How will the system interact with the external world to acquire resources? (e.g. get data or spawn virtual machines\n",
    "We can access data directly from a specified weblink or path for the dataset within the established repo. relative paths using APIs if necessary can be set in the notebooks to make this happen.\n",
    "\n",
    "#### 10.3.1 How does the system decide how much of an external resource is needed? (e.g. how many virtual CPUs are required during training?) \n",
    "N/A\n",
    "\n",
    "## 11. Description of how the system will scale:\n",
    "### 11.1 With increasing dataset sizes: \n",
    "There is no current plan for scaling the system to adapt to large datasets.\n",
    "\n",
    "### 11.2 With increasing numbers of models being used:\n",
    "The number of models used should not affect the scalability of the project.\n",
    "\n",
    "### 11.3 With increasing numbers of parameters:\n",
    "N/A\n",
    "\n",
    "### 11.4 With increasing numbers of divergences/losses:\n",
    "N/A\n",
    "\n",
    "## 12. Description of how the system will interface with external systems:\n",
    "- **E.g. if a model needs to be served in Go but it was trained in Python…**\n",
    "- **If the system needs to manipulate Kubernetes for training...**\n",
    "\n",
    "N/A\n",
    "\n",
    "## 13. Description of how errors will be handled:\n",
    "### 13.1 What are common expected errors from users and how can we guard against them?\n",
    "Having a wrong specification for a desired model, pylogit has built-in mechanisms to guard against it\n",
    "Having the wrong parameters or wrong parameter format in each of the functions/classes used in the project. Detailed docstrings will be used to help users figure out the needed parameters in each function along with their format. The initial parameter initialization will also help users see example use cases of the functions.\n",
    "### 13.2 Will we try to fix errors or merely notify users of the error’s presence?\n",
    "We will only notify users of the error's presence.\n",
    "\n",
    "### 13.3 When errors are encountered, will we quit immediately or wait until some specified point before notifying users of errors? For which errors is each strategy appropriate?\n",
    "Quit immediately in the case of all errors.\n",
    "\n",
    "### 13.4 What are the conventions for error messages that the system reports?\n",
    "No specific convention is set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5 Where are errors processed? At the point of detection, by a central error handling class, by functions above in the call stack, etc.\n",
    "Errors are processed at the point of detection.\n",
    "\n",
    "### 13.6 What level of responsibility does each class have in validating its own input? Is there a central class (or set of classes) that performs all validation? When can classes assume clean information?\n",
    "Code for input validation can be built in separate functions and be used part of analysis functions as seen needed.\n",
    "\n",
    "### 13.7 How will we use (or not use) type hinting to help prevent errors?\n",
    "Docstrings will suggest to the users what each of the function takes in as types and what it returns.\n",
    "`mypy` is an additional option to be used for type hinting withing each of the functions.\n",
    "\n",
    "## 14. Description of testing plan:\n",
    "### 14.1 How will we test that all of the parts of the architecture are working correctly?\n",
    "- **How will we create tests for each part of the architecture that are:**\n",
    " - **clear and unambiguous**\n",
    " - **capable of dealing with stochastic functions / objects**\n",
    " - **minimizing reliance / use of stochasticity**\n",
    " - **fast to evaluate**\n",
    "\n",
    "The first thing that comes to mind is running the same tests (probably using `hypothesis`?)\n",
    "many times and then verify that the output statistics match one's expectations. In order for tests to be fast, each\n",
    "test will need to focus on one functionality. We can have docstrings/clear names explaining what each test function is doing (the naming convention in pytest makes this easy). Each test should also be independent from other tests.\n",
    "\n",
    "### 14.2 What are the various types of tests that are needed?\n",
    "Unit tests/Feature tests, integration tests.\n",
    "\n",
    "### 14.3 Are there any parts of the architecture that we do not know how to test? How will these knowledge gaps be resolved before the coding begins?\n",
    "Given our preliminary knowledge on testing, there will be elements that we won't know how to test. \n",
    "Reading through available documentation and tutorials for pytest or other packages will help resolve any knowledge gaps \n",
    "in testing any of the parts of the architecture.\n",
    "\n",
    "### 14.4 How will discovered bugs be turned into test cases?\n",
    "The guide provided by Timothy on how to debug code will be followed to move from finding the bug to testing it.\n",
    "\n",
    "### 14.5 How will the software be reviewed in general (beyond automated tests) to reduce the probability of programming bugs into the code / increase the chance of producing correctly functioning software?\n",
    "Cross-review between team members will help in detecting any bugs or any testing gaps.\n",
    "\n",
    "## 15. Description of project-sharing procedures:\n",
    "### 15.1 Is there a plan in place for producing documentation for the software?\n",
    "- **Documentation for operating the software**\n",
    "- **Documentation of software limits**\n",
    "- **Usage examples and tutorials**\n",
    "- **Key project learnings / retrospective notes**\n",
    "\n",
    "Documentation, in the form of Jupyter Notebook accompanied by a Markdown file (README.md) detailing the procedure for installing the environment and the content of folders and notebooks. Any limitations to the project will be noted in the jupyter notebooks developed to illustrate the analysis effort. The README.md markdown file will also will point to documentation pages for any packages used in the project.\n",
    "\n",
    "For each of the functions and classes written for this project, we will write detailed docstrings that help with how the functions\n",
    "and classes function and what they output.\n",
    "\n",
    "### 15.2 Is there a plan for sharing the software with others?\n",
    "- **File upload?**\n",
    "- **Upload to package repository?**\n",
    "\n",
    "All project related material including code, documentation, presentation, environment files, and datasets will be uploaded to the project github repository.\n",
    "\n",
    "### 15.3 Will the project have an associated website? If so is there a plan for its development?\n",
    "The only \"website\" for the project will be its github repository.\n",
    "\n",
    "### 15.4 Is there a plan for producing any written or visual materials that others may wish to view?\n",
    "- **Final or interim project reports**\n",
    "- **Tables of key project results**\n",
    "- **Graphs, diagrams, images from the project, e.g.:**\n",
    " - **Plots of system performance**\n",
    " - **Model checking plots**\n",
    " \n",
    "**This was directly taken from the requirements document**\n",
    "\n",
    "1. Public notebooks\n",
    "   1. Selection-on-observables simulation:\n",
    "      - How are our causal effect estimates impacted by using an incorrect causal graph, in the simplest and most ideal setting?\n",
    "   2. Deconfounder demonstration with data from Brathwaite and Walker's asymmetric models paper.\n",
    "      - Does the deconfounder approach substantially change the estimated causal effects and inferred sensititivities?\n",
    "   3. Deconfounder investigation based on simplified simulations\n",
    "      - What are the potential pitfalls of the deconfounder approach? How can we look out for them?\n",
    "   4. Deconfounder demonstration using realistically simulated data based on data in Brathwaite and Walkders asymmetric models paper.\n",
    "      - Are our results obtained with the real data qualitatively consistent with results obtained on realistically simulated data that we know satisfy the deconfounders assumptions?\n",
    "   5. Demonstration of falsification techniques.\n",
    "      - How can we test the assumptions underlying our proposed / hypothesized causal graphs?\n",
    "2. Resulting plots / tables\n",
    "   - Selection-on-observables simulation\n",
    "      - Correctly estimated vs True causal effect of travel distance reduction on automobile mode shares (drive alone + shared_ride_2 + shared_ride_3+).\n",
    "      - Naively estimated vs True causal effect of travel distance reduction on automobile mode shares (drive alone + shared_ride_2 + shared_ride_3+).\n",
    "   - Simplified / Illustrative Deconfounder simulations\n",
    "      - Plots of misleading p-value conclusions when using posterior predictive checks.\n",
    "      - Plots of alternative posterior predictive checks of the factor model for one's deconfounder.\n",
    "      - Plots of the relationship between confounder inference error and outcome model parameter bias.\n",
    "   - Deconfounder demonstration with real data\n",
    "      - Plots of asymptotic distributions of model coefficients with and without the inferred deconfounders.\n",
    "      - Plots of predicted distributions (based on the asymptotic distribution of model coefficients) of causal effects with and without the inferred deconfounders.\n",
    "   - Deconfounder demonstration with realistically simulated data.\n",
    "      - Plots of asymptotic distributions of model coefficients with and without the inferred deconfounders.\n",
    "      - Plots of predicted distributions (based on the asymptotic distribution of model coefficients) of causal effects with and without the inferred deconfounders.\n",
    "      - Comparison of the two plots above next to those same plots based on the real data.  \n",
    "      We want to know if the results observed using the real data are qualitatively consistent with the results obtained using data that we know satisfies the deconfounder assumptions.\n",
    "   - Falsification tests\n",
    "      - Causal graph for Utility Drive Alone.\n",
    "      - Marginal independence test statistic distribution vs observed value, for causal graph of Utility Drive Alone graph.\n",
    "      - Conditional independence test statistic distribution vs observed value, for causal graph of Utility Drive Alone graph.\n",
    "      - Deconfounder causal graph for Utility Drive Alone\n",
    "      - Prior and posterior predictive test statistic distribution for conditional independence test statistics vs observed test statistic value.\n",
    "3. Supporting source code.\n",
    "   - Selection-on-observables\n",
    "      - Function(s) for estimating some statistical model for each treatment node given its parents.\n",
    "      - Function for simulating data from a specified causal graph, the estimated statistical models of each treatment node given its parents, and a given outcome model given the treatment nodes.\n",
    "      - Function for re-estimating a given outcome model, conditional on a set of simulated data for the parents of the outcome nodes.\n",
    "      - Function for estimating causal effects given a specified causal graph and relationships between  nodes and their parents.\n",
    "      - Function for plotting the distributions of estimated causal effects under various causal graphs and relationships between nodes and their parents.\n",
    "\n",
    "   - Deconfounder\n",
    "      - Function for fitting factor model  \n",
    "        A class with a few of factor model methods:  \n",
    "        Probabilistic PCA, Deep exponential family, Poisson Matrix Factorization?\n",
    "          1. Inputs:\n",
    "             - Matrix of covariates\n",
    "             - Dimensionality of latent variable space\n",
    "             - Type of factor model to be estimated\n",
    "          2. Output: A fitted factor model\n",
    "      - Function for prior predictive checks of the factor models.\n",
    "         1. Inputs:\n",
    "            - Factor model\n",
    "            - Training data\n",
    "            - Prior distributions of factor model parameters\n",
    "         2. Outputs: P-values and plots for predictive checks\n",
    "      - Function for posterior predictive checks for the factor models.  \n",
    "         1. Inputs:\n",
    "            - Factor model\n",
    "            - Training and/or testing data\n",
    "            - Posterior distributions of factor model parameters\n",
    "          2. Output: P-values and plots for predictive checks\n",
    "   - Falsification of causal graphs\n",
    "      - Function for marginal independence tests\n",
    "      - Function for conditional independence tests\n",
    "      - Function for prior/posterior predictive conditional independence tests\n",
    "4. Tests for all source code and notebooks.\n",
    "   1. [At Minimum] Integration tests of public notebooks.\n",
    "   2. [At Minimum] Unit tests of all critical / top-level / non-trivial / non-standard functions.\n",
    "   3. [Ideally] Unit tests of all source code.\n",
    "\n",
    "## 16 Description of maintenance plan:\n",
    "### 16.1 How will the system / software be maintained after initial creation?\n",
    "\n",
    "The source code of the project will be improved/expanded by adding more capabilities as needed.\n",
    "\n",
    "### 16.2 What needs to be done for maintenance?\n",
    "The source code for any functions/classes will be modified following the github workflow. One will submit an issue showing the bug/need for extension with a minimal working example or desired output, followed by a pull request with fixed code or added features. The pull request will be merged once code is reviewed by team. Refactoring will make this process easier as it will be smoother to isolate the issue and make any needed extensions of functionality. \n",
    "\n",
    "### 16.3 Who will perform needed maintenance activities?\n",
    "Hassan/Amine, and other interested students in Joan's group.\n",
    "\n",
    "## 17. Description of project tools:\n",
    "### 17.1 What are all the tools and major external systems upon which the project depends?\n",
    "Standard scientific packages such as: numpy, pandas, scipy, pylogit, causalgraphicalmodels(or others),\n",
    "seaborn/matplotlib, scikitlearn, pyro, fitter, pytest. This list is not exhaustive and could grow.\n",
    "\n",
    "### 17.2 Is there evidence that we understand the basics of how all of those tools work?\n",
    "- **Have we read any/all relevant documentation and instruction materials?**\n",
    "- **Have we taken any basic training courses in any of these tools?**\n",
    "\n",
    "Each team members is individually familiar working with the majority of these packages. Collectively, the team is\n",
    "familiar working with all of these packages. If additional packages are needed and no team member has the expertise\n",
    "needed to work with them, the team will make sure to read any available documentation or use examples available. \n",
    "\n",
    "## 18. Description of project risks and mitigation efforts:\n",
    "### 18.1  There should be some evidence for, and of, project feasibility:\n",
    "- **How do we know that every part of the architecture will work?**\n",
    "- **Based on the architecture, what are all needed resources?**\n",
    "\n",
    "The architecture is mainly based on third party dependencies that have proven to work. The needed resources will be\n",
    "one's laptop with an installed environments/requirements and compatible python version. For any functions/classes developed as part of this project, we will write tests that will ensure that we get the expected outputs.\n",
    "\n",
    "### 18.2 What could render the project infeasible?\n",
    "- **Is there adequate resourcing?**\n",
    "\n",
    "We do not envision inadequate resourcing problems to occur.\n",
    "\n",
    "### 18.3 Are there known sources of difficulty based on the planned tasks?\n",
    "The sources of difficulty are related to learning proper software engineering practices and learning about new\n",
    "third party dependencies. Additionally, getting comfortable with some of the methods used in the project has proven to be a roadblock at times.\n",
    "\n",
    "### 18.4 Are there mismatches between prior knowledge and required tasks?\n",
    "Yes, this is mitigated by reading literature on methods to be used, or documentation of python or any third party dependencies used in the project.\n",
    "\n",
    "### 18.5 What are the weakest areas of the architecture?\n",
    "- **Where is the project most vulnerable to failure?**\n",
    "- **How are these weaknesses being addressed?**\n",
    "At this moment, the weakest areas of the architecture are as follows:\n",
    "- The lack of tests in the available code and the lack of refactoring that could make it hard for use by other outside users.\n",
    "- The lack of a project workflow file to enable reproduction of the final results. I think this one will be fairly \n",
    "  straightforward to make, assuming we follow good practices of creating modular notebooks and code. **(Currently in progress)**\n",
    "- The lack of a reproducible experiment system. We have no way to track all the different ideas that are likely about \n",
    "  to be tried in the next month to get final results. Afterwards, we will then be unable/less-able to reproduce our work\n",
    "  along the way to the final results. As a result, we'll be unable/less-able to harvest any useful information from this\n",
    "  period since it's more difficult to use the knowledge of what didn't work if you don't remember all the things that didn't work.\n",
    "\n",
    "## 19. Description of the approach to over-engineering:\n",
    "### To what extent should planning be done to prevent all errors versus to produce the simplest system necessitated by the requirements?\n",
    "Planning should be done at incremental levels to avoid missing any potential error when planning for a large system.\n",
    "Planning could be done at the function/small task level for example.\n",
    "\n",
    "## 20.  Description of change strategy:\n",
    "### 20.1 What steps are being taken to ensure that the architecture is able to handle changes with maximal ease / flexibility? e.g.:\n",
    "- **Newly desired capabilities based on usage of initial iterations**\n",
    "- **Adding planned features that didn’t make it to the minimal viable product**\n",
    "- **Allowing for easy change of third party dependencies**\n",
    "- **Complying with any relevant standards for maximal compatibility with outside products**\n",
    "- **New ways of interaction with users (e.g. avoiding type checking as much as possible in favor of duck-typing)**\n",
    "- **Are classes maximally independent such that changes in one class don’t necessitate changes in the others?**\n",
    "- **Do we have a plan in place for test changes? For example if needing to change the data used in a test, can that be easily done without having to rewrite the test? E.g. data stored outside the code, or integration tests that don’t test for a specific prediction output but rather a property of the prediction outputs so that the model can change without the test necessitating a rewrite.**\n",
    "\n",
    "The team members will write functions and classes that are as independent as possible to make changes easy to implement.\n",
    "Tests will be rewritten accordingly.\n",
    "\n",
    "The source code will be refactored and will comply with PEP8 for easier readability for new users and contributors. \n",
    "\n",
    "We have no currently established plan for ease of change of third party dependencies.\n",
    "\n",
    "### 20.2 What is the strategy for handling requests for new features from or updates of the system after its built?\n",
    "Issues will be posted to the github repository and assigned to one of the team members. The team member will add\n",
    "the requested feature and submit a pull request for review by other team members. Once the review process is over, the \n",
    "change and new feature can be merged to the master branch.\n",
    "\n",
    "### 20.3 How will bug-fixes be handled? By whom?\n",
    "Bug fixes will be prioritized based on importance and urgency. Each bug fix will be handled by a team member most\n",
    "comfortable with the source code for the sake of efficiency. The debugging code shared by Timothy will be key in fixing any bugs in the code. Fixing bugs will also follow the github workflow starting with submitting an issue and creating a branch for fixing the bug, all the way until merging the branch to `master`.\n",
    "\n",
    "## 21.  Description of reuse strategy:\n",
    "### How is the architecture maximally leveraging previously completed work?\n",
    "The architecture makes uses of many third party dependencies for data ingestion, data processing, analysis, and \n",
    "producing output. The team members are trying to write as little new code that replicates existing functionality \n",
    "as possible.\n",
    "\n",
    "## 22. Description of architectural alternatives (i.e. alternatives to how to carry out the project):\n",
    "### 22.1 What are the closest alternative systems that could be used for this project or for parts of the project?\n",
    "- **How can those alternate systems be leveraged?**\n",
    "\n",
    "We are unaware of any alternative systems that accomplish exactly what we would like to accomplish in this project.\n",
    "\n",
    "### 22.2 Why is it expected that this project’s custom built sub-systems will be better than the available alternatives for those sub-systems?\n",
    "\n",
    "We are unaware of any available alternatives for any of the required tasks in this project.\n",
    "\n",
    "## 23. Description of architectural alternatives (i.e. alternatives to how to carry out the project):\n",
    "### 23.1 What were alternative ways to architect the system to satisfy the requirements?\n",
    "- **If there were no other alternatives, then why were there no other alternatives and can we prove this was really the case?**\n",
    "\n",
    "No transportation researchers have addressed the problems we are tackling in this project, to our best knowledge.\n",
    "We can not prove that no alternatives exist.\n",
    "\n",
    "### 23.2 Why did we choose to architect the system the way we did?\n",
    "\n",
    "- What were our objectives in choosing the given architecture?\n",
    "- What were the motivations for all major decisions?\n",
    "\n",
    "The architecture was incrementally designed to respond to evolving project objectives. The main objective is to design the architecture in a way that satisfied the project objectives and makes the code easily reusable and extensible for any user who has a basic knowledge of Python. Additionally, we want to make it provide the three deliverables needed for the project.\n",
    "\n",
    "## 24. Description of expected debugging protocol:\n",
    "### Should detail the expected debugging process to be used when, despite all of our planning and checking, failure is experienced while using some piece of the implemented architecture.\n",
    "The debugging protocol to be followed was outlined by Timothy and is available as one of the references in the repo.\n",
    "## 25. Final checks:\n",
    "### Do any parts of the system seem over- or under-architected. Empirically, are the descriptions of any sub-component much more thorough than any other?\n",
    "All the subsystems right now aim to deliver the minimum viable product. This means that these systems could be\n",
    "under-architected. This will be adjusted as more insight is gained about how the different pieces of the system should\n",
    "function interactively."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
