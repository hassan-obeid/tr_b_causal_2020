{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# # Selection on Observables\n",
    "# ## Purpose\n",
    "# The purpose of this notebook is to illustrate an example of the workflow outlined in [Brathwaite and Walker (2017)](https://arxiv.org/abs/1706.07502). This simple application aims at highlighting the importance of causal structure in estimating causal effects of interest reflecting changes resulting from policy proposals. The basic idea is to show that when we control for intermediate variables of some variable of interest in a causal graph, we never recover the true causal parameter on the variable of interest.\n",
    "#\n",
    "# This notebook uses the dataset and the MNL utility specification from [Brathwaite and Walker (2016)](https://arxiv.org/abs/1606.05900) for demonstration.\n",
    "# The rest of the notebook is organized as follows:\n",
    "#  - Defining different causal graphs representing different views for how individuals make mode choices. These causal graphs are based on the MNL utility functions from [Brathwaite and Walker (2016)](https://arxiv.org/abs/1606.05900)\n",
    "#  - Simulating data based on the different beliefs about the data generating process illustrated by both causal graphs.\n",
    "#  - Perturbing one of the variables (e.g.: Travel Distance) to simulate a policy intervention.\n",
    "#  - Calculating and plotting the distributions of treatment effects according to different causal graphs.\n",
    "# # Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import copy\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from functools import reduce\n",
    "\n",
    "import causal2020.observables.availability as av\n",
    "import causal2020.observables.distfit as distfit\n",
    "import causal2020.observables.regression as reg\n",
    "import causal2020.observables.simulation as sim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylogit as pl\n",
    "import seaborn as sns\n",
    "from causal2020.observables.graphs import BIKE_UTILITY\n",
    "from causal2020.observables.graphs import DA_UTILITY\n",
    "from causal2020.observables.graphs import DTW_UTILITY\n",
    "from causal2020.observables.graphs import IND_UTILITY\n",
    "from causal2020.observables.graphs import SHARED_2_UTILITY\n",
    "from causal2020.observables.graphs import SHARED_3P_UTILITY\n",
    "from causal2020.observables.graphs import WALK_UTILITY\n",
    "from causal2020.observables.graphs import WTD_UTILITY\n",
    "from causal2020.observables.graphs import WTW_UTILITY\n",
    "from causal2020.observables.utils import is_notebook\n",
    "from causalgraphicalmodels import CausalGraphicalModel\n",
    "from checkrs.utils import simulate_choice_vector\n",
    "from pyprojroot import here\n",
    "\n",
    "# Third party libraries\n",
    "# Local libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 197\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Path to Data\n",
    "DATA_PATH = here(\n",
    "    \"data/raw/spring_2016_all_bay_area_long_format_plus_cross_bay_col.csv\"\n",
    ")\n",
    "\n",
    "# Path to computational code used\n",
    "# in simulation loop\n",
    "SIMULATE_NODES_WIDE = open(\n",
    "    here(\"src/causal2020/observables/simworkflow.py\")\n",
    ").read()\n",
    "SIMULATE_PERTURB = open(\n",
    "    here(\"src/causal2020/observables/simperturb.py\")\n",
    ").read()\n",
    "\n",
    "# Path to storage location for plots with results\n",
    "TRUE_VS_NAIVE_PLOT_PATH = here(\"article/images/histogram_selection_on_obs.pdf\")\n",
    "TRUE_VS_ESTIMATED_PLOT_PATH = here(\n",
    "    \"reports/figures/historgram_true_vs_estimated_effects.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative id column from long format data\n",
    "ALT_ID_COL = \"mode_id\"\n",
    "\n",
    "# Individual specific variables list\n",
    "IND_SPEC_VARS = [\n",
    "    \"household_size\",\n",
    "    \"num_kids\",\n",
    "    \"num_cars\",\n",
    "    \"num_licensed_drivers\",\n",
    "]\n",
    "\n",
    "# Alternative specific variables dictionary\n",
    "# Key is alternative number, value is a list\n",
    "# of alternative specific nodes without parents\n",
    "ALT_SPEC_DICT = {\n",
    "    1: [\"total_travel_distance\"],\n",
    "    2: [\"total_travel_distance\"],\n",
    "    3: [\"total_travel_distance\"],\n",
    "    4: [\"total_travel_time\"],\n",
    "    5: [\"total_travel_time\"],\n",
    "    6: [\"total_travel_time\"],\n",
    "    7: [\"total_travel_distance\"],\n",
    "    8: [\"total_travel_distance\"],\n",
    "}\n",
    "\n",
    "# Trip specific variables list\n",
    "TRIP_SPEC_VARS = [\"cross_bay\"]\n",
    "\n",
    "# Alternative name dictionary\n",
    "# Key is alternative number\n",
    "# value is alternative number snake cased\n",
    "ALT_NAME_DICT = {\n",
    "    1: \"drive_alone\",\n",
    "    2: \"shared_2\",\n",
    "    3: \"shared_3p\",\n",
    "    4: \"wtw\",\n",
    "    5: \"dtw\",\n",
    "    6: \"wtd\",\n",
    "    7: \"walk\",\n",
    "    8: \"bike\",\n",
    "}\n",
    "\n",
    "ALT_ID_TO_MODE_NAME = {\n",
    "    1: \"Drive Alone\",\n",
    "    2: \"Shared Ride 2\",\n",
    "    3: \"Shared Ride 3+\",\n",
    "    4: \"Walk-Transit-Walk\",\n",
    "    5: \"Drive-Transit-Walk\",\n",
    "    6: \"Walk-Transit-Drive\",\n",
    "    7: \"Walk\",\n",
    "    8: \"Bike\",\n",
    "}\n",
    "\n",
    "# Variable type Dictionary\n",
    "# Key is string with variable name from previous\n",
    "# dictionaries and lists, value is a string\n",
    "# with type of the variable\n",
    "VARS_TYPE = {\n",
    "    \"num_kids\": \"categorical\",\n",
    "    \"household_size\": \"categorical\",\n",
    "    \"num_cars\": \"categorical\",\n",
    "    \"num_licensed_drivers\": \"categorical\",\n",
    "    \"cross_bay\": \"categorical\",\n",
    "    \"total_travel_time\": \"continuous\",\n",
    "    \"total_travel_distance\": \"continuous\",\n",
    "    \"total_travel_cost\": \"continuous\",\n",
    "}\n",
    "\n",
    "# Distribution to be explored for continuous variables\n",
    "CONT_DISTS = [\"norm\", \"alpha\", \"beta\", \"gamma\", \"expon\", \"gumbel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare regression parameters\n",
    "\n",
    "REGS_DA = {\n",
    "    1: (\"total_travel_distance\", \"total_travel_cost\"),\n",
    "    2: (\"total_travel_distance\", \"total_travel_time\"),\n",
    "}\n",
    "\n",
    "REGS_TYPE_DA = {1: \"linear\", 2: \"linear\"}\n",
    "\n",
    "\n",
    "REGS_SHARED_2 = {\n",
    "    1: (\"total_travel_distance\", \"total_travel_cost\"),\n",
    "    2: (\"total_travel_distance\", \"total_travel_time\"),\n",
    "}\n",
    "\n",
    "REGS_TYPE_SHARED_2 = {1: \"linear\", 2: \"linear\"}\n",
    "\n",
    "\n",
    "REGS_SHARED_3P = {\n",
    "    1: (\"total_travel_distance\", \"total_travel_cost\"),\n",
    "    2: (\"total_travel_distance\", \"total_travel_time\"),\n",
    "}\n",
    "\n",
    "REGS_TYPE_SHARED_3P = {1: \"linear\", 2: \"linear\"}\n",
    "\n",
    "\n",
    "REGS_WTW = {1: (\"total_travel_time\", \"total_travel_cost\")}\n",
    "\n",
    "REGS_TYPE_WTW = {1: \"linear\"}\n",
    "\n",
    "\n",
    "REGS_DTW = {1: (\"total_travel_time\", \"total_travel_cost\")}\n",
    "\n",
    "REGS_TYPE_DTW = {1: \"linear\"}\n",
    "\n",
    "\n",
    "REGS_WTD = {1: (\"total_travel_time\", \"total_travel_cost\")}\n",
    "\n",
    "REGS_TYPE_WTD = {1: \"linear\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for conversion from Wide to Long\n",
    "\n",
    "IND_VARIABLES = [\n",
    "    \"num_kids\",\n",
    "    \"household_size\",\n",
    "    \"num_cars\",\n",
    "    \"num_licensed_drivers\",\n",
    "    \"cross_bay\",\n",
    "]\n",
    "\n",
    "\n",
    "# Dictionary of Alternative Specific Variables\n",
    "# TODO: verify whether all variables are needed\n",
    "# for each alternative\n",
    "ALT_VARYING_VARIABLES = {\n",
    "    u\"total_travel_time\": dict(\n",
    "        [\n",
    "            (1, \"total_travel_time_drive_alone\"),\n",
    "            (2, \"total_travel_time_shared_2\"),\n",
    "            (3, \"total_travel_time_shared_3p\"),\n",
    "            (4, \"total_travel_time_wtw\"),\n",
    "            (5, \"total_travel_time_dtw\"),\n",
    "            (6, \"total_travel_time_wtd\"),\n",
    "        ]\n",
    "    ),\n",
    "    u\"total_travel_cost\": dict(\n",
    "        [\n",
    "            (1, \"total_travel_cost_drive_alone\"),\n",
    "            (2, \"total_travel_cost_shared_2\"),\n",
    "            (3, \"total_travel_cost_shared_3p\"),\n",
    "            (4, \"total_travel_cost_wtw\"),\n",
    "            (5, \"total_travel_cost_dtw\"),\n",
    "            (6, \"total_travel_cost_wtd\"),\n",
    "        ]\n",
    "    ),\n",
    "    u\"total_travel_distance\": dict(\n",
    "        [\n",
    "            (1, \"total_travel_distance_drive_alone\"),\n",
    "            (2, \"total_travel_distance_shared_2\"),\n",
    "            (3, \"total_travel_distance_shared_3p\"),\n",
    "            (7, \"total_travel_distance_walk\"),\n",
    "            (8, \"total_travel_distance_bike\"),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary of alternative availability variables\n",
    "AVAILABILITY_VARIABLES = {\n",
    "    1: \"drive_alone_AV\",\n",
    "    2: \"shared_2_AV\",\n",
    "    3: \"shared_3p_AV\",\n",
    "    4: \"wtw_AV\",\n",
    "    5: \"dtw_AV\",\n",
    "    6: \"wtd_AV\",\n",
    "    7: \"walk_AV\",\n",
    "    8: \"bike_AV\",\n",
    "}\n",
    "\n",
    "##########\n",
    "# Determine the columns for: alternative ids, the observation ids and the choice\n",
    "##########\n",
    "# The 'custom_alt_id' is the name of a column to be created in the long-format data\n",
    "# It will identify the alternative associated with each row.\n",
    "CUSTOM_ALT_ID = \"mode_id\"\n",
    "\n",
    "OBS_ID_COL = \"observation_id\"\n",
    "\n",
    "# Declare choice column\n",
    "CHOICE_COL = \"sim_choice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my specification and variable names for the basic MNL model\n",
    "# NOTE: - Keys should be variables within the long format dataframe.\n",
    "#         The sole exception to this is the \"intercept\" key.\n",
    "#       - For the specification dictionary, the values should be lists\n",
    "#         or lists of lists. Within a list, or within the inner-most\n",
    "#         list should be the alternative ID's of the alternative whose\n",
    "#         utility specification the explanatory variable is entering.\n",
    "\n",
    "MNL_SPECIFICATION = OrderedDict()\n",
    "MNL_NAMES = OrderedDict()\n",
    "\n",
    "MNL_SPECIFICATION[\"intercept\"] = [2, 3, 4, 5, 6, 7, 8]\n",
    "MNL_NAMES[\"intercept\"] = [\n",
    "    \"ASC Shared Ride: 2\",\n",
    "    \"ASC Shared Ride: 3+\",\n",
    "    \"ASC Walk-Transit-Walk\",\n",
    "    \"ASC Drive-Transit-Walk\",\n",
    "    \"ASC Walk-Transit-Drive\",\n",
    "    \"ASC Walk\",\n",
    "    \"ASC Bike\",\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"total_travel_time\"] = [[1, 2, 3], [4, 5, 6]]\n",
    "MNL_NAMES[\"total_travel_time\"] = [\n",
    "    \"Travel Time, units:min (All Auto Modes)\",\n",
    "    \"Travel Time, units:min (All Transit Modes)\",\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"total_travel_cost\"] = [[4, 5, 6]]\n",
    "MNL_NAMES[\"total_travel_cost\"] = [\"Travel Cost, units:$ (All Transit Modes)\"]\n",
    "\n",
    "MNL_SPECIFICATION[\"cost_per_distance\"] = [1, 2, 3]\n",
    "MNL_NAMES[\"cost_per_distance\"] = [\n",
    "    \"Travel Cost per Distance, units:$/mi (Drive Alone)\",\n",
    "    \"Travel Cost per Distance, units:$/mi (SharedRide-2)\",\n",
    "    \"Travel Cost per Distance, units:$/mi (SharedRide-3+)\",\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"cars_per_licensed_drivers\"] = [[1, 2, 3]]\n",
    "MNL_NAMES[\"cars_per_licensed_drivers\"] = [\n",
    "    \"Autos per licensed drivers (All Auto Modes)\"\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"total_travel_distance\"] = [7, 8]\n",
    "MNL_NAMES[\"total_travel_distance\"] = [\n",
    "    \"Travel Distance, units:mi (Walk)\",\n",
    "    \"Travel Distance, units:mi (Bike)\",\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"cross_bay\"] = [1, [2, 3]]\n",
    "MNL_NAMES[\"cross_bay\"] = [\n",
    "    \"Cross-Bay Tour (Drive Alone)\",\n",
    "    \"Cross-Bay Tour (Shared Ride 2 & 3+)\",\n",
    "]\n",
    "\n",
    "MNL_SPECIFICATION[\"household_size\"] = [[2, 3]]\n",
    "MNL_NAMES[\"household_size\"] = [\"Household Size (Shared Ride 2 & 3+)\"]\n",
    "\n",
    "MNL_SPECIFICATION[\"num_kids\"] = [[2, 3]]\n",
    "MNL_NAMES[\"num_kids\"] = [\"Number of Kids in Household (Shared Ride 2 & 3+)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from the specified PATH\n",
    "bike_data_long = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Look at the mode shares in the data set\n",
    "\n",
    "mode_counts = (\n",
    "    bike_data_long.loc[bike_data_long.choice == 1, \"mode_id\"]\n",
    "    .value_counts()\n",
    "    .loc[range(1, 9)]\n",
    ")\n",
    "\n",
    "mode_shares = mode_counts / bike_data_long.observation_id.max()\n",
    "mode_shares.index = [ALT_ID_TO_MODE_NAME[x] for x in mode_shares.index.values]\n",
    "mode_shares.name = \"Mode Shares\"\n",
    "mode_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Model Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of this task, we use the MNL specification from Brathwaite and Walker (2016) and estimate the model resulting from such a specification. We assume that the estimated model parameters represent the \"true\" model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the basic MNL model, using the hessian and newton-conjugate gradient\n",
    "mnl_model = pl.create_choice_model(\n",
    "    data=bike_data_long,\n",
    "    alt_id_col=ALT_ID_COL,\n",
    "    obs_id_col=OBS_ID_COL,\n",
    "    choice_col=\"choice\",\n",
    "    specification=MNL_SPECIFICATION,\n",
    "    model_type=\"MNL\",\n",
    "    names=MNL_NAMES,\n",
    ")\n",
    "\n",
    "num_vars = len(reduce(lambda x, y: x + y, MNL_NAMES.values()))\n",
    "\n",
    "# Note newton-cg used to ensure convergence to a point where gradient\n",
    "# is essentially zero for all dimensions.\n",
    "mnl_model.fit_mle(np.zeros(num_vars), method=\"BFGS\")\n",
    "\n",
    "# Look at the estimation results\n",
    "mnl_model.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Causal Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate two causal graphs based on the data at hand and the specified utility functions from above:\n",
    "\n",
    " * An \"independent\" causal graph: All nodes are independent and do not affect each other. Any change in any variable in the graph would not result in changes in other variables and would only affect the value of the utility function.\n",
    " * A \"realistic\" causal graph: The structure of this causal graph shows that some variables affect others. In this example, a change in travel distance affects travel time, travel cosst, and directly affects the utility function.\n",
    "\n",
    "The outcome of each of the causal graphs is the utility of each variable. As such, we generate causal graphs based on the utility specification for each alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Causal Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realistic Causal Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED_2_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED_3P_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Transit-Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTW_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive-Transit-Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Walk-Transit-Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTD_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALK_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIKE_UTILITY.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection on Observables Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate data based on the assumed structure of the causal diagrams and the original data from [Brathwaite and Walker (2016)](https://arxiv.org/abs/1606.05900). This process goes as follows:\n",
    "\n",
    "For the independent causal graph:\n",
    " * We fit a probability distribution for all the nodes in the utility function\n",
    "\n",
    "For the realistic causal graph:\n",
    " * We fit a probability distribution for all the nodes without any parents/upstream notes in the causal graphs\n",
    " * We fit any regressions between the related explanatory variables\n",
    "\n",
    "Based on these fitted distributions and regressions, we can then simulate data for the remaining nodes in each of the alternatives in our specified model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_params = distfit.get_dist_node_no_parent(\n",
    "    bike_data_long,\n",
    "    ALT_ID_COL,\n",
    "    OBS_ID_COL,\n",
    "    ALT_SPEC_DICT,\n",
    "    ALT_NAME_DICT,\n",
    "    IND_SPEC_VARS,\n",
    "    TRIP_SPEC_VARS,\n",
    "    VARS_TYPE,\n",
    "    CONT_DISTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the structure of the \"realistic\" causal graphs assumed for each of the alternatives, we fit regressions that will allow us to simulate the remaining nodes in the causal graphs. The utility node will be simulated based on the utility function for each alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_alone_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 1]\n",
    "\n",
    "drive_alone_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_da = reg.fit_alternative_regression(\n",
    "    regressions=REGS_DA, reg_types=REGS_TYPE_DA, data=drive_alone_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_2_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 2]\n",
    "\n",
    "shared_2_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_shared_2 = reg.fit_alternative_regression(\n",
    "    regressions=REGS_SHARED_2, reg_types=REGS_TYPE_SHARED_2, data=shared_2_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_3p_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 3]\n",
    "\n",
    "shared_3p_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_shared_3p = reg.fit_alternative_regression(\n",
    "    regressions=REGS_SHARED_3P,\n",
    "    reg_types=REGS_TYPE_SHARED_3P,\n",
    "    data=shared_3p_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Transit-Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtw_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 4]\n",
    "\n",
    "wtw_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_wtw = reg.fit_alternative_regression(\n",
    "    regressions=REGS_WTW, reg_types=REGS_TYPE_WTW, data=wtw_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive-Transit-Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 5]\n",
    "\n",
    "dtw_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_dtw = reg.fit_alternative_regression(\n",
    "    regressions=REGS_DTW, reg_types=REGS_TYPE_DTW, data=dtw_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Transit-Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd_df = bike_data_long.loc[bike_data_long[\"mode_id\"] == 6]\n",
    "\n",
    "wtd_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fitted_reg_wtd = reg.fit_alternative_regression(\n",
    "    regressions=REGS_WTD, reg_types=REGS_TYPE_WTD, data=wtd_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the probability distributions of parent nodes and identifying the relationships between connected nodes allows us to complete the selection-on-observables simulation. The workflow proceeds as follows:\n",
    "* Simulate two sets of data for the X variables:\n",
    "  - One where all the Xs are independent (i.e. the only edges in the causal graph are between the X and the outcome variable (which is the value of the utility function)).\n",
    "  - One based on a realistic causal graph with confounders. The confounder in this simple example is Travel Distance.\n",
    "* For each of the two causal graphs mentioned in the previous step, simulate choice data based on the outcome model assumed from [Brathwaite and Walker (2016)](https://arxiv.org/abs/1606.05900).\n",
    "* Estimate the choice model for each of those two datasets using the assumed choice model specification.\n",
    "* Apply the do-operator (perturbation) to the variable of interest (Travel Distance), and show that the predicted outcome would be accurate only if our causal graph captures the dependency between the explanatory variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, we want 200 simulations, but if we're using this file as a python\n",
    "# script in a CI, use 30 simulations so the CI terminates quickly.\n",
    "NUM_SIMULATIONS = 200 if is_notebook() else 30\n",
    "simulation_sizes = np.random.randint(low=3000, high=4000, size=NUM_SIMULATIONS)\n",
    "sim_number = np.arange(1, 1 + NUM_SIMULATIONS)\n",
    "models_dictionary = defaultdict(dict)\n",
    "causal_effect_dictionary = {}\n",
    "perturb = 0.8\n",
    "simulation_data = {}\n",
    "causal_effects = pd.DataFrame(\n",
    "    columns=[\"naive_effect\", \"true_effect\", \"estimated_effect\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim_size, number in zip(simulation_sizes, sim_number):\n",
    "    print(\"Simulation number\", number, \"is in progress...\")\n",
    "    print(\"Simulation size is\", sim_size)\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Simulating data...\")\n",
    "    # Simulate data without parents\n",
    "    sim_bike_data_no_parent = sim.sim_node_no_parent(\n",
    "        params_dict=bike_data_params, size=sim_size\n",
    "    )\n",
    "\n",
    "    sim_bike_data_wide = copy.deepcopy(sim_bike_data_no_parent)\n",
    "\n",
    "    # Simulate nodes based on causal graphs\n",
    "    exec(SIMULATE_NODES_WIDE)\n",
    "\n",
    "    # Converting Data from Wide to Long\n",
    "    print(\"Converting data from wide to long...\")\n",
    "    long_sim_data = pl.convert_wide_to_long(\n",
    "        wide_data=sim_bike_data_wide,\n",
    "        ind_vars=IND_VARIABLES,\n",
    "        alt_specific_vars=ALT_VARYING_VARIABLES,\n",
    "        availability_vars=AVAILABILITY_VARIABLES,\n",
    "        obs_id_col=OBS_ID_COL,\n",
    "        choice_col=CHOICE_COL,\n",
    "        new_alt_id_name=CUSTOM_ALT_ID,\n",
    "    )\n",
    "\n",
    "    # Create a cars per licensed drivers column\n",
    "    long_sim_data[\"cars_per_licensed_drivers\"] = 0\n",
    "    long_sim_data.loc[\n",
    "        long_sim_data.num_licensed_drivers > 0, \"cars_per_licensed_drivers\"\n",
    "    ] = long_sim_data.num_cars / long_sim_data.num_licensed_drivers.astype(\n",
    "        float\n",
    "    )\n",
    "\n",
    "    # Add a variable representing cost divided by distance\n",
    "    long_sim_data[\"cost_per_distance\"] = 0\n",
    "    long_sim_data.loc[\n",
    "        long_sim_data.mode_id.isin([1, 2, 3]), \"cost_per_distance\"\n",
    "    ] = (\n",
    "        long_sim_data.loc[\n",
    "            long_sim_data.mode_id.isin([1, 2, 3]), \"total_travel_cost\"\n",
    "        ]\n",
    "        / long_sim_data.loc[\n",
    "            long_sim_data.mode_id.isin([1, 2, 3]), \"total_travel_distance\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Simulating Choices\n",
    "    print(\"Simulating Choices...\")\n",
    "    # Calculate probabilities for each alternative\n",
    "    # based on the estimated model\n",
    "    init_mnl_model_probs = mnl_model.predict(long_sim_data)\n",
    "\n",
    "    # Simulate choice data\n",
    "    long_sim_data[CHOICE_COL] = simulate_choice_vector(\n",
    "        predicted_probs=init_mnl_model_probs,\n",
    "        observation_ids=long_sim_data[OBS_ID_COL].values,\n",
    "    )\n",
    "\n",
    "    # Estimating Choice Models\n",
    "    print(\"Estimating the choice model...\")\n",
    "    # Estimate the basic MNL model, using the hessian and newton-conjugate gradient\n",
    "    mnl_model_sim = pl.create_choice_model(\n",
    "        data=long_sim_data,\n",
    "        alt_id_col=ALT_ID_COL,\n",
    "        obs_id_col=OBS_ID_COL,\n",
    "        choice_col=CHOICE_COL,\n",
    "        specification=MNL_SPECIFICATION,\n",
    "        model_type=\"MNL\",\n",
    "        names=MNL_NAMES,\n",
    "    )\n",
    "\n",
    "    num_vars = len(reduce(lambda x, y: x + y, MNL_NAMES.values()))\n",
    "    # Note newton-cg used to ensure convergence to a point where gradient\n",
    "    # is essentially zero for all dimensions.\n",
    "    mnl_model_sim_params = mnl_model_sim.fit_mle(\n",
    "        np.zeros(num_vars), method=\"BFGS\", just_point=True\n",
    "    )\n",
    "    mnl_model_sim_param_list = [mnl_model_sim_params[\"x\"], None, None, None]\n",
    "    models_dictionary[number] = mnl_model_sim\n",
    "\n",
    "    print(\"Estimating Causal Effects...\")\n",
    "\n",
    "    # Estimating Causal Effects\n",
    "    # Create copies of long format data\n",
    "    long_sim_data_naive = copy.deepcopy(long_sim_data)\n",
    "    long_sim_data_causal = copy.deepcopy(long_sim_data)\n",
    "\n",
    "    # Initial Probabilities\n",
    "    init_mnl_model_sim_probs = mnl_model_sim.predict(\n",
    "        long_sim_data, param_list=mnl_model_sim_param_list\n",
    "    )\n",
    "\n",
    "    long_sim_data[\"init_mnl_model_sim_probs\"] = init_mnl_model_sim_probs\n",
    "\n",
    "    # mnl_model_probs = mnl_model.predict(long_sim_data)\n",
    "    long_sim_data[\"init_mnl_model_probs\"] = init_mnl_model_probs\n",
    "\n",
    "    long_sim_data_naive[\"total_travel_distance\"] = (\n",
    "        perturb * long_sim_data_naive[\"total_travel_distance\"]\n",
    "    )\n",
    "    long_sim_data_causal[\"total_travel_distance\"] = (\n",
    "        perturb * long_sim_data[\"total_travel_distance\"]\n",
    "    )\n",
    "\n",
    "    # Naive Probabilities\n",
    "    naive_probabilities = mnl_model_sim.predict(\n",
    "        long_sim_data_naive, param_list=mnl_model_sim_param_list\n",
    "    )\n",
    "\n",
    "    long_sim_data_naive[\"naive_probabilities\"] = naive_probabilities\n",
    "\n",
    "    # Estimated Probabilities\n",
    "\n",
    "    exec(SIMULATE_PERTURB)\n",
    "\n",
    "    # Compute Estimated Probabilities\n",
    "    estimated_probabilities = mnl_model_sim.predict(\n",
    "        long_sim_data_causal, param_list=mnl_model_sim_param_list\n",
    "    )\n",
    "    long_sim_data_causal[\"estimated_probabilities\"] = estimated_probabilities\n",
    "\n",
    "    # True Probabilities\n",
    "    true_probabilities = mnl_model.predict(long_sim_data_causal)\n",
    "    long_sim_data_causal[\"true_probabilities\"] = true_probabilities\n",
    "\n",
    "    simulation_data[number] = {}\n",
    "    simulation_data[number][\"long_sim_data\"] = long_sim_data\n",
    "    simulation_data[number][\"long_sim_data_causal\"] = long_sim_data_causal\n",
    "    simulation_data[number][\"long_sim_data_naive\"] = long_sim_data_naive\n",
    "\n",
    "    print(\"Simulation number\", number, \"is complete!\")\n",
    "    print(\"==========================================\")\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Effect Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the causal effect related to the perturbation of the Travel Distance variable in each of the causal graphs (independent and realistic) on the probability of choosing Driving based modes (Drive alone, Shared-2, and Shared-3+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in sim_number:\n",
    "\n",
    "    initial_data = simulation_data[number][\"long_sim_data\"]\n",
    "    naive_data = simulation_data[number][\"long_sim_data_naive\"]\n",
    "    causal_data = simulation_data[number][\"long_sim_data_causal\"]\n",
    "\n",
    "    naive_effect = (\n",
    "        naive_data.loc[\n",
    "            naive_data[\"mode_id\"].isin([1, 2, 3]), \"naive_probabilities\"\n",
    "        ]\n",
    "        - initial_data.loc[\n",
    "            initial_data[\"mode_id\"].isin([1, 2, 3]), \"init_mnl_model_sim_probs\"\n",
    "        ]\n",
    "    )\n",
    "    estimated_effect = (\n",
    "        causal_data.loc[\n",
    "            causal_data[\"mode_id\"].isin([1, 2, 3]), \"estimated_probabilities\"\n",
    "        ]\n",
    "        - initial_data.loc[\n",
    "            initial_data[\"mode_id\"].isin([1, 2, 3]), \"init_mnl_model_sim_probs\"\n",
    "        ]\n",
    "    )\n",
    "    true_effect = (\n",
    "        causal_data.loc[\n",
    "            causal_data[\"mode_id\"].isin([1, 2, 3]), \"true_probabilities\"\n",
    "        ]\n",
    "        - initial_data.loc[\n",
    "            initial_data[\"mode_id\"].isin([1, 2, 3]), \"init_mnl_model_probs\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    causal_effects = causal_effects.append(\n",
    "        {\n",
    "            \"true_effect\": true_effect.mean(),\n",
    "            \"estimated_effect\": estimated_effect.mean(),\n",
    "            \"naive_effect\": naive_effect.mean(),\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the distribution of the causal effects to show the bias in predicted outcomes based on the assumed causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "FONTSIZE = 13\n",
    "HIST_ALPHA = 0.7\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.distplot(\n",
    "    causal_effects.true_effect,\n",
    "    label=\"True Effect\",\n",
    "    kde=False,\n",
    "    color=\"#005AB5\",\n",
    "    hist_kws={\"alpha\": HIST_ALPHA},\n",
    ")\n",
    "sns.distplot(\n",
    "    causal_effects.naive_effect,\n",
    "    label=\"Naive Effect\",\n",
    "    kde=False,\n",
    "    color=\"#DC3220\",\n",
    "    hist_kws={\"alpha\": HIST_ALPHA},\n",
    ")\n",
    "plt.title(\n",
    "    \"True Effect vs. Naive Effect\",\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.ylabel(\n",
    "    \"Frequency\",\n",
    "    rotation=90,\n",
    "    labelpad=5,\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"Average Causal Effect\",\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.legend(prop={\"size\": FONTSIZE})\n",
    "sns.despine()\n",
    "plt.savefig(TRUE_VS_NAIVE_PLOT_PATH, dpi=500, bbox_inches=\"tight\")\n",
    "if is_notebook():\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.distplot(\n",
    "    causal_effects.true_effect,\n",
    "    label=\"True Effect\",\n",
    "    kde=False,\n",
    "    color=\"#005AB5\",\n",
    "    hist_kws={\"alpha\": HIST_ALPHA},\n",
    ")\n",
    "sns.distplot(\n",
    "    causal_effects.estimated_effect,\n",
    "    label=\"Estimated Effect\",\n",
    "    kde=False,\n",
    "    color=\"#994F00\",\n",
    "    hist_kws={\"alpha\": HIST_ALPHA},\n",
    ")\n",
    "plt.title(\n",
    "    \"True Effect vs. Estimated Effect\",\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.ylabel(\n",
    "    \"Frequency\",\n",
    "    rotation=90,\n",
    "    labelpad=5,\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"Average Causal Effect\",\n",
    "    fontdict={\"fontsize\": FONTSIZE, \"fontweight\": \"bold\"},\n",
    ")\n",
    "plt.legend(prop={\"size\": FONTSIZE})\n",
    "sns.despine()\n",
    "plt.savefig(TRUE_VS_ESTIMATED_PLOT_PATH, dpi=500, bbox_inches=\"tight\")\n",
    "if is_notebook():\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main conclusion from this notebook is that assigning causal intepretations to model parameters is only valid if we draw clear assumptions about the data generation process about the question at hand. The data generating process was shown to be important even as the outcome model remained unchanged. Drawing a causal graph (and testing its validity with the data at hand) allows one to clearly state their assumptions about the data generating process and to clearly assign causal interpretations to specific model parameters."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
