{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from fitter import Fitter\n",
    "#import attr\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pylogit as pl\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Fitting Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitDistribution(object):\n",
    "    \"\"\"Fit and simulate data to known distributions.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    - data: array-like or dataframe.\n",
    "    - dists: list.\n",
    "        This parameter contains a list of distributions to be explored.\n",
    "        When None, every available distribution on scipy is explored.\n",
    "    - bins: int. \n",
    "        Numbers of bins to be used for the cumulative histogram. This has\n",
    "        an impact on the quality of the fit.\n",
    "    - timeout: int. \n",
    "        Maximum time for a given distribution. If timeout is reached, \n",
    "        the distribution is skipped.\n",
    "        \"\"\"\n",
    "    def __init__(self, data, dists=None, timeout=30, verbose=False, bins=100):\n",
    "        self.data = data\n",
    "        #self.var_types = var_types\n",
    "        self.dists = dists\n",
    "        self.timeout = timeout\n",
    "        self.verbose = verbose\n",
    "        self.bins = bins\n",
    "        self.ArrayDistDict = defaultdict()\n",
    "        self.params_dict = defaultdict(dict)\n",
    "\n",
    "    def FindArrayDist(self, cat_var):\n",
    "        \"\"\"Function to extract the best distribution for a specified array.\n",
    "        Uses the fit method from the Fitter module in the fitter library\n",
    "        Inputs:\n",
    "        -------\n",
    "        - cat_var: boolean\n",
    "            Boolean to signify whether the variable to be simulated\n",
    "            is discrete/categorical or continuous.\n",
    "        \n",
    "        Outputs:\n",
    "        -------\n",
    "        By default, the function returns a dictionary with best distribution name\n",
    "        and parameters associated with it. If a number of distributions\n",
    "        was specified, the function returns a pandas DataFrame with\n",
    "        the N best distributions, along with a plot showing all of them.\"\"\"\n",
    "        self.ArrayDistDict = dict()\n",
    "        if  cat_var == True:\n",
    "            self.ArrayDistDict['distribution'] = 'categorical'\n",
    "            np_array_range = np.arange(self.data.max()+1)\n",
    "            array_bincount = np.bincount(self.data)\n",
    "            probs = array_bincount / len(self.data)\n",
    "            \n",
    "            self.ArrayDistDict['parameters'] = [np_array_range,\n",
    "                                                probs]            \n",
    "        else:\n",
    "            fitter_object = Fitter(data=self.data,\n",
    "                                   distributions=self.dists,\n",
    "                                   timeout=self.timeout)\n",
    "            fitter_object.fit()\n",
    "            BestDict = fitter_object.get_best()\n",
    "            self.ArrayDistDict['distribution'] = list(BestDict.items())[0][0]\n",
    "            self.ArrayDistDict['parameters'] = list(BestDict.items())[0][1]\n",
    "        return self.ArrayDistDict\n",
    "    \n",
    "    def SimArray(self, size=100):\n",
    "        \"\"\"Function to simulate data for an array based on the best fitted\n",
    "        distribution.\n",
    "        Input:\n",
    "        -----\n",
    "        - size : int\n",
    "                size of the array to be simulated.\n",
    "        Outputs:\n",
    "        -------\n",
    "        Simulated array based on the best fit distribution.\"\"\"\n",
    "        if self.ArrayDistDict['distribution'] == 'categorical':\n",
    "            Sim_Array = np.random.choice(a=self.ArrayDistDict['parameters'][0],\n",
    "                                         p=self.ArrayDistDict['parameters'][1],\n",
    "                                         size=size)\n",
    "        else:\n",
    "            dist = getattr(scipy.stats, self.ArrayDistDict['distribution'])\n",
    "            Sim_Array = dist.rvs(*self.ArrayDistDict['parameters'], size=size)\n",
    "        return Sim_Array\n",
    "    \n",
    "    def FindDfDist(self, var_types):\n",
    "        \"\"\"Function to extract the best distribution from a specified dataframe.\n",
    "        Uses the function find_dist, which in turn uses the fit method from the\n",
    "        Fitter module in the fitter library\n",
    "        Inputs:\n",
    "        -------\n",
    "        - var_types: dictionary\n",
    "            Dictionary with keys as column names for dataset variables, the value\n",
    "            of each key is a string showing whether the variable is discrete/cat\n",
    "            or continuous.\n",
    "\n",
    "        Outputs:\n",
    "        -------\n",
    "        *FOR NOW*, the function returns a dictionary showing the best distribution\n",
    "        name for each array in the dataframe and parameters associated with it.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        for column in list(self.data.columns):\n",
    "            \n",
    "            if  var_types[column] == 'categorical':\n",
    "                if len(self.data[column].unique()) == 1:\n",
    "                    self.params_dict[column]['distribution'] = 'constant'\n",
    "                    self.params_dict[column]['parameters'] = self.data[column].unique()\n",
    "                else:\n",
    "                    self.params_dict[column]['distribution'] = 'categorical'\n",
    "                    np_array_range = np.arange(self.data[column].max()+1)\n",
    "                    array_bincount = np.bincount(self.data[column])\n",
    "                    probs = array_bincount / len(self.data[column])\n",
    "                    self.params_dict[column]['parameters'] = [np_array_range,\n",
    "                                                              probs]            \n",
    "            else:\n",
    "                if len(self.data[column].unique()) == 1:\n",
    "                    self.params_dict[column]['distribution'] = 'constant'\n",
    "                    self.params_dict[column]['parameters'] = self.data[column].unique()\n",
    "                else:\n",
    "                    fitter_object = Fitter(data=self.data[column],\n",
    "                                           distributions=self.dists,\n",
    "                                           timeout=self.timeout)\n",
    "                    fitter_object.fit()\n",
    "                    BestDict = fitter_object.get_best()\n",
    "                    self.params_dict[column]['distribution'] = list(BestDict.items())[0][0]\n",
    "                    self.params_dict[column]['parameters'] = list(BestDict.items())[0][1]\n",
    "        return self.params_dict\n",
    "\n",
    "    def SimDf(self, size=1000):\n",
    "        \"\"\"Funtion to simulate data of size N based on specified\n",
    "        distribution/parameters found by the fitter package.\n",
    "        Inputs:\n",
    "        -------\n",
    "        data: dataframe from which columns are to be taken\n",
    "        dist_params: the distribution parameters from find_dist_df\n",
    "        Outputs:\n",
    "        -------\n",
    "        DataFrame object with simulated data based on specified distributions\n",
    "        \"\"\"\n",
    "        Sim_Df = pd.DataFrame(columns=list(self.params_dict.keys()))\n",
    "        Sim_Df = Sim_Df.fillna(0)\n",
    "        for column in list(self.params_dict.keys()):\n",
    "            if self.params_dict[column]['distribution'] == 'categorical':\n",
    "                data_sim = np.random.choice(a=self.params_dict[column]['parameters'][0],\n",
    "                                            p=self.params_dict[column]['parameters'][1],\n",
    "                                            size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "            elif self.params_dict[column]['distribution'] == 'constant':\n",
    "                data_sim = self.params_dict[column]['parameters'][0]\n",
    "                Sim_Df[column] = data_sim\n",
    "            else:\n",
    "                dist = getattr(scipy.stats, self.params_dict[column]['distribution'])\n",
    "                data_sim = dist.rvs(*self.params_dict[column]['parameters'], size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "        return Sim_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to calculate probabilities for each alternative **(to be replaced by functions from the choice_tools module in pylogit)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept_to_df(df_long, specification_dict):\n",
    "    \n",
    "    if (\"intercept\" in specification_dict \n",
    "        and \"intercept\" not in df_long.columns):\n",
    "        df_long[\"intercept\"] = 1\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_design_matrix(df_long, specification_dict,\n",
    "                         names_dict, alternative_id_col):\n",
    "    \n",
    "    add_intercept_to_df(df_long,specification_dict)\n",
    "    \n",
    "    columns = []\n",
    "    for col in specification_dict:\n",
    "        for group in specification_dict[col]:\n",
    "            if type(group) == list:\n",
    "                columns.append(df_long[alternative_id_col].isin(group)\n",
    "                               *df_long[col])\n",
    "            else:\n",
    "                columns.append((df_long[alternative_id_col]==group)\n",
    "                               *df_long[col])\n",
    "    \n",
    "    design_matrix = np.stack(columns,axis = 1)\n",
    "    \n",
    "    var_names = []\n",
    "    for variable in names_dict:\n",
    "        for name in names_dict[variable]:\n",
    "            var_names.append(name)\n",
    "    \n",
    "    return design_matrix, var_names\n",
    "\n",
    "\n",
    "def calculate_utilities(betas, design_matrix):\n",
    "    \n",
    "    limit_max = 700\n",
    "    limit_min = -700 \n",
    "    \n",
    "    utility = design_matrix.dot(betas)\n",
    "    utility[utility>limit_max] = limit_max\n",
    "    utility[utility<limit_min] = limit_min\n",
    "    \n",
    "    utilities = np.exp(utility)\n",
    "    \n",
    "    return utilities\n",
    "\n",
    "\n",
    "def create_mapping_matrix(df_long, observation_id_col):\n",
    "    row_to_col_matrix = pd.get_dummies(df_long[observation_id_col]).values\n",
    "#     row_to_col_matrix = (df_long[observation_id_col].values[:,None] == \n",
    "#                          np.sort(df_long[observation_id_col].unique())[None,:]).astype(int) \n",
    "    sparse_row_to_col_matrix = sparse.csr_matrix(row_to_col_matrix)\n",
    "    \n",
    "    mapping_matrix = sparse_row_to_col_matrix.dot(sparse_row_to_col_matrix.T)\n",
    "    \n",
    "    return mapping_matrix\n",
    "\n",
    "\n",
    "def calculate_probabilities(betas,design_matrix, mapping_matrix):\n",
    "    \n",
    "    utilities = calculate_utilities(betas, design_matrix)\n",
    "    denominator = mapping_matrix.dot(utilities)\n",
    "    probabilities = utilities/denominator\n",
    "    probabilities[probabilities==0] = 1e-300\n",
    "    \n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to simulate choices based on long data format (This will be potentially extended to simulate choices directly from wide data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimulateChoices(data, alt_id_col, obs_id_col, number_alts, spec_dic, names_dic, init_betas):\n",
    "\n",
    "# This commented out block is to extend the capabilities of the function from simulating choices\n",
    "# only based on long data to wide data. The logic is built out completely, all we need is to \n",
    "# refactor it and adjust the parameters in the function definition.\n",
    "#     choice_var = 'choice'\n",
    "#     custom_alt_id = \"alternative_id\"\n",
    "#     obs_id_column = \"custom_id\"\n",
    "\n",
    "#     # Adding a Choice Variable Column\n",
    "#     data[choice_var] = np.random.randint(1, high=number_alts+1, size=data.shape[0])\n",
    "#     availability_variables = dict()\n",
    "\n",
    "#     # Adding availability variables and specifying alternative availability numbers\n",
    "#     for alt in np.arange(1, number_alts+1, 1):\n",
    "#         data['AV_' + str(alt)] = 1\n",
    "#         availability_variables[alt] = 'AV_' + str(alt)\n",
    "\n",
    "#     # Specifying the Individual Variables\n",
    "#     ind_variables = ind_variables\n",
    "\n",
    "#     alt_varying_variables = alt_var_vars\n",
    "#     # Specifying the column heading for the alternative id column in the\n",
    "#     # long format dataset\n",
    "#     custom_alt_id = \"alternative_id\"\n",
    "#     obs_id_column = \"custom_id\"\n",
    "#     sample_data[obs_id_column] = np.arange(sample_data.shape[0],\n",
    "#                                            dtype=int) + 1\n",
    "\n",
    "#     # Create a variable recording the choice column\n",
    "\n",
    "#     long_data = pl.convert_wide_to_long(wide_data=sample_data,\n",
    "#                                         ind_vars=ind_variables,\n",
    "#                                         alt_specific_vars=alt_varying_variables,\n",
    "#                                         availability_vars=availability_variables,\n",
    "#                                         obs_id_col=obs_id_column,\n",
    "#                                         choice_col=choice_var,\n",
    "#                                         new_alt_id_name=custom_alt_id)\n",
    "    sim_choice_var = 'sim_choice'\n",
    "    # Functions to generate the probabilities for each alternative\n",
    "\n",
    "    long_data = data\n",
    "\n",
    "    design_matrix, names = create_design_matrix(df_long=long_data,\n",
    "                                                specification_dict=mnl_specification,\n",
    "                                                names_dict=mnl_names,\n",
    "                                                alternative_id_col=alt_id_col)\n",
    "    mapping_matrix = create_mapping_matrix(df_long=long_data,\n",
    "                                           observation_id_col=obs_id_col)\n",
    "    probabilities = calculate_probabilities(betas=initial_betas,\n",
    "                                            design_matrix=design_matrix,\n",
    "                                            mapping_matrix=mapping_matrix)\n",
    "\n",
    "    data['probabilities'] = probabilities\n",
    "    data['cum_sum'] = 0\n",
    "    data['sim_choice'] = 0\n",
    "\n",
    "    for observation in data['observation_id'].unique():\n",
    "        probs_sum = data[data.observation_id==observation]['probabilities'].cumsum()\n",
    "        data.loc[data['observation_id']==observation,'cum_sum'] = probs_sum\n",
    "\n",
    "    observation_id_list = list(data.observation_id.unique())\n",
    "    u_random = np.random.uniform(size = len(data['observation_id'].unique()))\n",
    "\n",
    "    for u,obs in zip(u_random,observation_id_list):\n",
    "        data_sample = data[data['observation_id']==obs]\n",
    "        sorted_list = sorted(list(data_sample['mode_id'].unique()))\n",
    "        choices = dict.fromkeys(sorted_list, 0)\n",
    "        for alt in sorted_list:   \n",
    "            choices[alt] = np.where(u<=data_sample[data_sample['mode_id']==alt]['cum_sum'], 1, 0).item()\n",
    "            if choices[alt] == 1:\n",
    "                break\n",
    "        data.loc[data.observation_id==obs,'sim_choice'] = data['mode_id'].map(choices)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using bike data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the path to the long format data for the multinomial choice model\n",
    "PATH = '/Users/mobouzaghrane/Documents/GitHub/tr_b_causal_2020/data/raw/spring_2016_all_bay_area_long_format_plus_cross_bay_col.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of bike_data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['household_id', 'person_id', 'tour_id', 'observation_id', 'mode_id',\n",
       "       'choice', 'tour_origin_taz', 'primary_dest_taz', 'total_travel_time',\n",
       "       'total_travel_cost', 'total_travel_distance', 'age', 'household_size',\n",
       "       'household_income', 'household_income_values', 'transit_subsidy',\n",
       "       'transit_subsidy_amount', 'num_cars', 'num_licensed_drivers',\n",
       "       'cross_bay', 'oakland_and_berkeley', 'survey_id', 'gender',\n",
       "       'non_relative_flag', 'num_pre_school', 'num_school_aged', 'married',\n",
       "       'parent', 'income_category_1', 'income_category_2', 'income_category_3',\n",
       "       'income_category_4', 'income_category_5', 'income_category_6',\n",
       "       'income_category_7', 'income_category_8', 'income_category_9',\n",
       "       'income_category_10', 'income_unknown', 'ln_drive_cost',\n",
       "       'ln_drive_cost_sq', 'total_travel_time_10x', 'total_travel_time_tenth',\n",
       "       'high_income', 'medium_income', 'low_income', 'high_income_cost',\n",
       "       'medium_income_cost', 'low_income_cost', 'unknown_income_cost',\n",
       "       'high_income_ln_cost', 'medium_income_ln_cost', 'low_income_ln_cost',\n",
       "       'unknown_income_ln_cost', 'cars_per_licensed_drivers', 'num_kids',\n",
       "       'family_in_household', 'married_woman', 'cost_per_distance',\n",
       "       'intercept', 'cost_per_distance_10$_per_mi',\n",
       "       'total_travel_time_tenth_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from the specified PATH\n",
    "bike_data_long = pd.read_csv(PATH)\n",
    "\n",
    "# If in previous work we accidentally saved the index with the dataframe\n",
    "# remove the old index from the data\n",
    "if \"Unnamed: 0\" in bike_data_long.columns:\n",
    "    del bike_data_long[\"Unnamed: 0\"]\n",
    "    \n",
    "print(\"The columns of bike_data are:\")\n",
    "bike_data_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drive Alone           0.428322\n",
       "Shared Ride 2         0.158841\n",
       "Shared Ride 3+        0.139860\n",
       "Walk-Transit-Walk     0.103397\n",
       "Drive-Transit-Walk    0.015485\n",
       "Walk-Transit-Drive    0.013237\n",
       "Walk                  0.094406\n",
       "Bike                  0.046454\n",
       "Name: Mode Shares, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the mode shares in the data set\n",
    "alt_id_to_mode_name = {1: \"Drive Alone\",\n",
    "                       2: \"Shared Ride 2\",\n",
    "                       3: \"Shared Ride 3+\",\n",
    "                       4: \"Walk-Transit-Walk\",\n",
    "                       5: \"Drive-Transit-Walk\",\n",
    "                       6: \"Walk-Transit-Drive\",\n",
    "                       7: \"Walk\",\n",
    "                       8: \"Bike\"}\n",
    "\n",
    "mode_counts = bike_data_long.loc[bike_data_long.choice==1,\n",
    "                            \"mode_id\"].value_counts().loc[range(1, 9)]\n",
    "\n",
    "mode_shares = mode_counts / bike_data_long.observation_id.max()\n",
    "mode_shares.index = [alt_id_to_mode_name[x] for x in mode_shares.index.values]\n",
    "mode_shares.name = \"Mode Shares\"\n",
    "mode_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL Model Specification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my specification and variable names for the basic MNL model\n",
    "# NOTE: - Keys should be variables within the long format dataframe.\n",
    "#         The sole exception to this is the \"intercept\" key.\n",
    "#       - For the specification dictionary, the values should be lists\n",
    "#         or lists of lists. Within a list, or within the inner-most\n",
    "#         list should be the alternative ID's of the alternative whose\n",
    "#         utility specification the explanatory variable is entering.\n",
    "\n",
    "mnl_specification = OrderedDict()\n",
    "mnl_names = OrderedDict()\n",
    "\n",
    "mnl_specification[\"intercept\"] = [2, 3, 4, 5, 6, 7, 8]\n",
    "mnl_names[\"intercept\"] = ['ASC Shared Ride: 2',\n",
    "                          'ASC Shared Ride: 3+',\n",
    "                          'ASC Walk-Transit-Walk',\n",
    "                          'ASC Drive-Transit-Walk',\n",
    "                          'ASC Walk-Transit-Drive',\n",
    "                          'ASC Walk',\n",
    "                          'ASC Bike']\n",
    "\n",
    "mnl_specification[\"total_travel_time\"] = [[1, 2, 3], [4, 5, 6]]\n",
    "mnl_names[\"total_travel_time\"] = ['Travel Time, units:min (All Auto Modes)',\n",
    "                                  'Travel Time, units:min (All Transit Modes)']\n",
    "\n",
    "mnl_specification[\"total_travel_cost\"] = [[4, 5, 6]]\n",
    "mnl_names[\"total_travel_cost\"] = ['Travel Cost, units:$ (All Transit Modes)']\n",
    "\n",
    "mnl_specification[\"cost_per_distance\"] = [1, 2, 3]\n",
    "mnl_names[\"cost_per_distance\"] = [\"Travel Cost per Distance, units:$/mi (Drive Alone)\",\n",
    "                                  \"Travel Cost per Distance, units:$/mi (SharedRide-2)\",\n",
    "                                  \"Travel Cost per Distance, units:$/mi (SharedRide-3+)\"]\n",
    "\n",
    "mnl_specification[\"cars_per_licensed_drivers\"] = [[1, 2, 3]]\n",
    "mnl_names[\"cars_per_licensed_drivers\"] = [\"Autos per licensed drivers (All Auto Modes)\"]\n",
    "\n",
    "mnl_specification[\"total_travel_distance\"] = [7, 8]\n",
    "mnl_names[\"total_travel_distance\"] = ['Travel Distance, units:mi (Walk)',\n",
    "                                      'Travel Distance, units:mi (Bike)']\n",
    "\n",
    "# mnl_specification[\"cross_bay\"] = [[2, 3], [4, 5, 6]]\n",
    "# mnl_names[\"cross_bay\"] = [\"Cross-Bay Tour (Shared Ride 2 & 3+)\",\n",
    "#                           \"Cross-Bay Tour (All Transit Modes)\"]\n",
    "mnl_specification[\"cross_bay\"] = [[2, 3]]\n",
    "mnl_names[\"cross_bay\"] = [\"Cross-Bay Tour (Shared Ride 2 & 3+)\"]\n",
    "\n",
    "mnl_specification[\"household_size\"] = [[2, 3]]\n",
    "mnl_names[\"household_size\"] = ['Household Size (Shared Ride 2 & 3+)']\n",
    "\n",
    "mnl_specification[\"num_kids\"] = [[2, 3]]\n",
    "mnl_names[\"num_kids\"] = [\"Number of Kids in Household (Shared Ride 2 & 3+)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -7,599.7019\n",
      "Initial Log-likelihood: -7,599.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/pylogit/choice_tools.py:703: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  design_matrix = np.hstack((x[:, None] for x in independent_vars))\n",
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py:505: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.18 seconds.\n",
      "Final log-likelihood: -5,073.4276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multinomial Logit Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>choice</td>          <th>  No. Observations:  </th>    <td>4,004</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>         <td>Multinomial Logit Model</td> <th>  Df Residuals:      </th>    <td>3,985</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>     <td>19</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 13 Mar 2020</td>     <th>  Pseudo R-squ.:     </th>    <td>0.332</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:06:18</td>         <th>  Pseudo R-bar-squ.: </th>    <td>0.330</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AIC:</th>                 <td>10,184.855</td>        <th>  Log-Likelihood:    </th> <td>-5,073.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIC:</th>                 <td>10,304.461</td>        <th>  LL-Null:           </th> <td>-7,599.702</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                            <td></td>                              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Shared Ride: 2</th>                                   <td>   -1.0097</td> <td>    0.486</td> <td>   -2.079</td> <td> 0.038</td> <td>   -1.962</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Shared Ride: 3+</th>                                  <td>    3.4619</td> <td>    1.064</td> <td>    3.254</td> <td> 0.001</td> <td>    1.377</td> <td>    5.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk-Transit-Walk</th>                                <td>   -0.3921</td> <td>    0.288</td> <td>   -1.360</td> <td> 0.174</td> <td>   -0.957</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Drive-Transit-Walk</th>                               <td>   -2.6220</td> <td>    0.303</td> <td>   -8.660</td> <td> 0.000</td> <td>   -3.215</td> <td>   -2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk-Transit-Drive</th>                               <td>   -2.9773</td> <td>    0.306</td> <td>   -9.725</td> <td> 0.000</td> <td>   -3.577</td> <td>   -2.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk</th>                                             <td>    1.5541</td> <td>    0.305</td> <td>    5.101</td> <td> 0.000</td> <td>    0.957</td> <td>    2.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Bike</th>                                             <td>   -1.1059</td> <td>    0.305</td> <td>   -3.628</td> <td> 0.000</td> <td>   -1.703</td> <td>   -0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Time, units:min (All Auto Modes)</th>              <td>   -0.0760</td> <td>    0.006</td> <td>  -13.728</td> <td> 0.000</td> <td>   -0.087</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Time, units:min (All Transit Modes)</th>           <td>   -0.0274</td> <td>    0.002</td> <td>  -12.768</td> <td> 0.000</td> <td>   -0.032</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost, units:$ (All Transit Modes)</th>             <td>   -0.1273</td> <td>    0.037</td> <td>   -3.472</td> <td> 0.001</td> <td>   -0.199</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (Drive Alone)</th>   <td>   -5.0613</td> <td>    1.377</td> <td>   -3.675</td> <td> 0.000</td> <td>   -7.760</td> <td>   -2.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (SharedRide-2)</th>  <td>  -20.3194</td> <td>    4.548</td> <td>   -4.467</td> <td> 0.000</td> <td>  -29.234</td> <td>  -11.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (SharedRide-3+)</th> <td>  -90.9224</td> <td>   14.748</td> <td>   -6.165</td> <td> 0.000</td> <td> -119.829</td> <td>  -62.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Autos per licensed drivers (All Auto Modes)</th>          <td>    1.2134</td> <td>    0.129</td> <td>    9.408</td> <td> 0.000</td> <td>    0.961</td> <td>    1.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Distance, units:mi (Walk)</th>                     <td>   -1.0272</td> <td>    0.050</td> <td>  -20.437</td> <td> 0.000</td> <td>   -1.126</td> <td>   -0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Distance, units:mi (Bike)</th>                     <td>   -0.2873</td> <td>    0.024</td> <td>  -11.896</td> <td> 0.000</td> <td>   -0.335</td> <td>   -0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cross-Bay Tour (Shared Ride 2 & 3+)</th>                  <td>    0.9280</td> <td>    0.327</td> <td>    2.839</td> <td> 0.005</td> <td>    0.287</td> <td>    1.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Household Size (Shared Ride 2 & 3+)</th>                  <td>    0.1136</td> <td>    0.045</td> <td>    2.523</td> <td> 0.012</td> <td>    0.025</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Kids in Household (Shared Ride 2 & 3+)</th>     <td>    0.6868</td> <td>    0.054</td> <td>   12.820</td> <td> 0.000</td> <td>    0.582</td> <td>    0.792</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     Multinomial Logit Model Regression Results                    \n",
       "===================================================================================\n",
       "Dep. Variable:                      choice   No. Observations:                4,004\n",
       "Model:             Multinomial Logit Model   Df Residuals:                    3,985\n",
       "Method:                                MLE   Df Model:                           19\n",
       "Date:                     Fri, 13 Mar 2020   Pseudo R-squ.:                   0.332\n",
       "Time:                             19:06:18   Pseudo R-bar-squ.:               0.330\n",
       "AIC:                            10,184.855   Log-Likelihood:             -5,073.428\n",
       "BIC:                            10,304.461   LL-Null:                    -7,599.702\n",
       "========================================================================================================================\n",
       "                                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------\n",
       "ASC Shared Ride: 2                                      -1.0097      0.486     -2.079      0.038      -1.962      -0.058\n",
       "ASC Shared Ride: 3+                                      3.4619      1.064      3.254      0.001       1.377       5.547\n",
       "ASC Walk-Transit-Walk                                   -0.3921      0.288     -1.360      0.174      -0.957       0.173\n",
       "ASC Drive-Transit-Walk                                  -2.6220      0.303     -8.660      0.000      -3.215      -2.029\n",
       "ASC Walk-Transit-Drive                                  -2.9773      0.306     -9.725      0.000      -3.577      -2.377\n",
       "ASC Walk                                                 1.5541      0.305      5.101      0.000       0.957       2.151\n",
       "ASC Bike                                                -1.1059      0.305     -3.628      0.000      -1.703      -0.508\n",
       "Travel Time, units:min (All Auto Modes)                 -0.0760      0.006    -13.728      0.000      -0.087      -0.065\n",
       "Travel Time, units:min (All Transit Modes)              -0.0274      0.002    -12.768      0.000      -0.032      -0.023\n",
       "Travel Cost, units:$ (All Transit Modes)                -0.1273      0.037     -3.472      0.001      -0.199      -0.055\n",
       "Travel Cost per Distance, units:$/mi (Drive Alone)      -5.0613      1.377     -3.675      0.000      -7.760      -2.362\n",
       "Travel Cost per Distance, units:$/mi (SharedRide-2)    -20.3194      4.548     -4.467      0.000     -29.234     -11.405\n",
       "Travel Cost per Distance, units:$/mi (SharedRide-3+)   -90.9224     14.748     -6.165      0.000    -119.829     -62.016\n",
       "Autos per licensed drivers (All Auto Modes)              1.2134      0.129      9.408      0.000       0.961       1.466\n",
       "Travel Distance, units:mi (Walk)                        -1.0272      0.050    -20.437      0.000      -1.126      -0.929\n",
       "Travel Distance, units:mi (Bike)                        -0.2873      0.024    -11.896      0.000      -0.335      -0.240\n",
       "Cross-Bay Tour (Shared Ride 2 & 3+)                      0.9280      0.327      2.839      0.005       0.287       1.569\n",
       "Household Size (Shared Ride 2 & 3+)                      0.1136      0.045      2.523      0.012       0.025       0.202\n",
       "Number of Kids in Household (Shared Ride 2 & 3+)         0.6868      0.054     12.820      0.000       0.582       0.792\n",
       "========================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the basic MNL model, using the hessian and newton-conjugate gradient\n",
    "mnl_model = pl.create_choice_model(data=bike_data_long,\n",
    "                                   alt_id_col=\"mode_id\",\n",
    "                                   obs_id_col=\"observation_id\",\n",
    "                                   choice_col=\"choice\",\n",
    "                                   specification=mnl_specification,\n",
    "                                   model_type=\"MNL\",\n",
    "                                   names=mnl_names)\n",
    "\n",
    "num_vars = len(reduce(lambda x, y: x + y, mnl_names.values()))\n",
    "# Note newton-cg used to ensure convergence to a point where gradient \n",
    "# is essentially zero for all dimensions. \n",
    "mnl_model.fit_mle(np.zeros(num_vars),\n",
    "                  method=\"BFGS\")\n",
    "\n",
    "# Look at the estimation results\n",
    "mnl_model.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store beta coefficients\n",
    "mnl_parameters = mnl_model.params\n",
    "\n",
    "# Store T-values\n",
    "mnl_tvalues = mnl_model.tvalues\n",
    "\n",
    "# Store P-values\n",
    "mnl_pvalues = mnl_model.pvalues\n",
    "\n",
    "# Store confidennce intervals for each of the model coefficients\n",
    "mnl_conf_int = mnl_model.conf_int(alpha=0.05, return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data - Based on Wide Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data from Long to Wide before simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model variables of interest are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['total_travel_time',\n",
       " 'total_travel_cost',\n",
       " 'cost_per_distance',\n",
       " 'cars_per_licensed_drivers',\n",
       " 'total_travel_distance',\n",
       " 'cross_bay',\n",
       " 'household_size',\n",
       " 'num_kids',\n",
       " 'mode_id',\n",
       " 'observation_id',\n",
       " 'choice',\n",
       " 'num_cars',\n",
       " 'num_licensed_drivers']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable list for subset of long data,\n",
    "# I will add the remaining values from the long format dataset\n",
    "alt_id_col = \"mode_id\"\n",
    "\n",
    "obs_id_col = \"observation_id\"\n",
    "\n",
    "choice_col = \"choice\"\n",
    "\n",
    "# Store of columns relevant to the data to be simulated\n",
    "model_variables = list(mnl_model.specification.keys())\n",
    "model_variables.remove('intercept')\n",
    "model_variables.extend([alt_id_col, obs_id_col, choice_col, 'num_cars', 'num_licensed_drivers'])\n",
    "print('The model variables of interest are:')\n",
    "model_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data subset\n",
    "subset_bike_data = bike_data_long[model_variables].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the needed variables for the conversion\n",
    "individual_specific_variables = ['num_kids','household_size',\n",
    "                                 'cars_per_licensed_drivers','cross_bay',\n",
    "                                 'num_cars','num_licensed_drivers']\n",
    "\n",
    "alternative_specific_variables = ['total_travel_time','total_travel_distance']\n",
    "\n",
    "subset_specific_variables = {'total_travel_cost': [1,2,3],\n",
    "                             'cost_per_distance': [1,2,3]}\n",
    "\n",
    "alternative_name_dict = {1: 'drive_alone',\n",
    "                         2: 'shared_2',\n",
    "                         3: 'shared_3p',\n",
    "                         4: 'wtw',\n",
    "                         5: 'dtw',\n",
    "                         6: 'wtd',\n",
    "                         7: 'walk',\n",
    "                         8: 'bike'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_id</th>\n",
       "      <th>choice</th>\n",
       "      <th>availability_drive_alone</th>\n",
       "      <th>availability_shared_2</th>\n",
       "      <th>availability_shared_3p</th>\n",
       "      <th>availability_wtw</th>\n",
       "      <th>availability_dtw</th>\n",
       "      <th>availability_wtd</th>\n",
       "      <th>availability_walk</th>\n",
       "      <th>availability_bike</th>\n",
       "      <th>...</th>\n",
       "      <th>total_travel_distance_dtw</th>\n",
       "      <th>total_travel_distance_wtd</th>\n",
       "      <th>total_travel_distance_walk</th>\n",
       "      <th>total_travel_distance_bike</th>\n",
       "      <th>total_travel_cost_drive_alone</th>\n",
       "      <th>total_travel_cost_shared_2</th>\n",
       "      <th>total_travel_cost_shared_3p</th>\n",
       "      <th>cost_per_distance_drive_alone</th>\n",
       "      <th>cost_per_distance_shared_2</th>\n",
       "      <th>cost_per_distance_shared_3p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>29.11</td>\n",
       "      <td>5.7140</td>\n",
       "      <td>3.2651</td>\n",
       "      <td>2.2856</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.105598</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.80</td>\n",
       "      <td>24.80</td>\n",
       "      <td>4.4519</td>\n",
       "      <td>2.5439</td>\n",
       "      <td>1.7807</td>\n",
       "      <td>0.184803</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.64</td>\n",
       "      <td>40.64</td>\n",
       "      <td>5.9782</td>\n",
       "      <td>3.4162</td>\n",
       "      <td>2.3913</td>\n",
       "      <td>0.184798</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   observation_id  choice  availability_drive_alone  availability_shared_2  \\\n",
       "0             1.0     2.0                         1                      1   \n",
       "1             2.0     2.0                         1                      1   \n",
       "2             3.0     1.0                         1                      1   \n",
       "3             4.0     1.0                         1                      1   \n",
       "4             5.0     1.0                         1                      1   \n",
       "\n",
       "   availability_shared_3p  availability_wtw  availability_dtw  \\\n",
       "0                       1                 1                 1   \n",
       "1                       1                 1                 1   \n",
       "2                       1                 1                 1   \n",
       "3                       1                 1                 1   \n",
       "4                       1                 0                 1   \n",
       "\n",
       "   availability_wtd  availability_walk  availability_bike  ...  \\\n",
       "0                 1                  1                  1  ...   \n",
       "1                 1                  1                  1  ...   \n",
       "2                 1                  1                  1  ...   \n",
       "3                 1                  1                  1  ...   \n",
       "4                 0                  1                  1  ...   \n",
       "\n",
       "   total_travel_distance_dtw  total_travel_distance_wtd  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        NaN   \n",
       "\n",
       "   total_travel_distance_walk  total_travel_distance_bike  \\\n",
       "0                       29.11                       29.11   \n",
       "1                       24.80                       24.80   \n",
       "2                        8.38                        8.38   \n",
       "3                        8.38                        8.38   \n",
       "4                       40.64                       40.64   \n",
       "\n",
       "   total_travel_cost_drive_alone  total_travel_cost_shared_2  \\\n",
       "0                         5.7140                      3.2651   \n",
       "1                         4.4519                      2.5439   \n",
       "2                         1.6817                      0.9609   \n",
       "3                         1.6817                      0.9609   \n",
       "4                         5.9782                      3.4162   \n",
       "\n",
       "   total_travel_cost_shared_3p  cost_per_distance_drive_alone  \\\n",
       "0                       2.2856                       0.184799   \n",
       "1                       1.7807                       0.184803   \n",
       "2                       0.6726                       0.184802   \n",
       "3                       0.6726                       0.184802   \n",
       "4                       2.3913                       0.184798   \n",
       "\n",
       "   cost_per_distance_shared_2  cost_per_distance_shared_3p  \n",
       "0                    0.105598                     0.073920  \n",
       "1                    0.105600                     0.073919  \n",
       "2                    0.105593                     0.073912  \n",
       "3                    0.105593                     0.073912  \n",
       "4                    0.105601                     0.073920  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data from long to wide, I assigned a null value of 0 \n",
    "# because it will make it easier to simulate data when we have\n",
    "# Unavailable variables\n",
    "bike_data_wide = pl.convert_long_to_wide(long_data=subset_bike_data,\n",
    "                                         ind_vars=individual_specific_variables,\n",
    "                                         alt_specific_vars=alternative_specific_variables,\n",
    "                                         subset_specific_vars=subset_specific_variables,\n",
    "                                         obs_id_col=obs_id_col,\n",
    "                                         alt_id_col=alt_id_col,\n",
    "                                         choice_col=choice_col,\n",
    "                                         alt_name_dict=alternative_name_dict)\n",
    "bike_data_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to decide how we will simulate data when we have unavailable values. TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_id</th>\n",
       "      <th>choice</th>\n",
       "      <th>availability_drive_alone</th>\n",
       "      <th>availability_shared_2</th>\n",
       "      <th>availability_shared_3p</th>\n",
       "      <th>availability_wtw</th>\n",
       "      <th>availability_dtw</th>\n",
       "      <th>availability_wtd</th>\n",
       "      <th>availability_walk</th>\n",
       "      <th>availability_bike</th>\n",
       "      <th>...</th>\n",
       "      <th>total_travel_distance_dtw</th>\n",
       "      <th>total_travel_distance_wtd</th>\n",
       "      <th>total_travel_distance_walk</th>\n",
       "      <th>total_travel_distance_bike</th>\n",
       "      <th>total_travel_cost_drive_alone</th>\n",
       "      <th>total_travel_cost_shared_2</th>\n",
       "      <th>total_travel_cost_shared_3p</th>\n",
       "      <th>cost_per_distance_drive_alone</th>\n",
       "      <th>cost_per_distance_shared_2</th>\n",
       "      <th>cost_per_distance_shared_3p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>29.11</td>\n",
       "      <td>5.7140</td>\n",
       "      <td>3.2651</td>\n",
       "      <td>2.2856</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.105598</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.80</td>\n",
       "      <td>24.80</td>\n",
       "      <td>4.4519</td>\n",
       "      <td>2.5439</td>\n",
       "      <td>1.7807</td>\n",
       "      <td>0.184803</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.64</td>\n",
       "      <td>40.64</td>\n",
       "      <td>5.9782</td>\n",
       "      <td>3.4162</td>\n",
       "      <td>2.3913</td>\n",
       "      <td>0.184798</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3333</td>\n",
       "      <td>3.1342</td>\n",
       "      <td>2.1940</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.184717</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.073962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4001</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.74</td>\n",
       "      <td>1.6448</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.184809</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.073910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4002</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.34</td>\n",
       "      <td>26.34</td>\n",
       "      <td>4.9360</td>\n",
       "      <td>2.8438</td>\n",
       "      <td>1.9907</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4003</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.19</td>\n",
       "      <td>25.19</td>\n",
       "      <td>4.3298</td>\n",
       "      <td>2.4742</td>\n",
       "      <td>1.7320</td>\n",
       "      <td>0.184797</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      observation_id  choice  availability_drive_alone  availability_shared_2  \\\n",
       "0                1.0     2.0                         1                      1   \n",
       "1                2.0     2.0                         1                      1   \n",
       "2                3.0     1.0                         1                      1   \n",
       "3                4.0     1.0                         1                      1   \n",
       "4                5.0     1.0                         1                      1   \n",
       "...              ...     ...                       ...                    ...   \n",
       "3999          4000.0     1.0                         1                      1   \n",
       "4000          4001.0     2.0                         1                      1   \n",
       "4001          4002.0     1.0                         1                      1   \n",
       "4002          4003.0     1.0                         1                      1   \n",
       "4003          4004.0     2.0                         1                      1   \n",
       "\n",
       "      availability_shared_3p  availability_wtw  availability_dtw  \\\n",
       "0                          1                 1                 1   \n",
       "1                          1                 1                 1   \n",
       "2                          1                 1                 1   \n",
       "3                          1                 1                 1   \n",
       "4                          1                 0                 1   \n",
       "...                      ...               ...               ...   \n",
       "3999                       1                 0                 0   \n",
       "4000                       1                 0                 0   \n",
       "4001                       1                 1                 1   \n",
       "4002                       1                 1                 1   \n",
       "4003                       1                 1                 1   \n",
       "\n",
       "      availability_wtd  availability_walk  availability_bike  ...  \\\n",
       "0                    1                  1                  1  ...   \n",
       "1                    1                  1                  1  ...   \n",
       "2                    1                  1                  1  ...   \n",
       "3                    1                  1                  1  ...   \n",
       "4                    0                  1                  1  ...   \n",
       "...                ...                ...                ...  ...   \n",
       "3999                 0                  1                  0  ...   \n",
       "4000                 0                  1                  0  ...   \n",
       "4001                 1                  1                  1  ...   \n",
       "4002                 1                  1                  1  ...   \n",
       "4003                 1                  1                  1  ...   \n",
       "\n",
       "      total_travel_distance_dtw  total_travel_distance_wtd  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        NaN   \n",
       "...                         ...                        ...   \n",
       "3999                        NaN                        NaN   \n",
       "4000                        NaN                        NaN   \n",
       "4001                        0.0                        0.0   \n",
       "4002                        0.0                        0.0   \n",
       "4003                        0.0                        0.0   \n",
       "\n",
       "      total_travel_distance_walk  total_travel_distance_bike  \\\n",
       "0                          29.11                       29.11   \n",
       "1                          24.80                       24.80   \n",
       "2                           8.38                        8.38   \n",
       "3                           8.38                        8.38   \n",
       "4                          40.64                       40.64   \n",
       "...                          ...                         ...   \n",
       "3999                       25.62                         NaN   \n",
       "4000                        1.06                         NaN   \n",
       "4001                        8.74                        8.74   \n",
       "4002                       26.34                       26.34   \n",
       "4003                       25.19                       25.19   \n",
       "\n",
       "      total_travel_cost_drive_alone  total_travel_cost_shared_2  \\\n",
       "0                            5.7140                      3.2651   \n",
       "1                            4.4519                      2.5439   \n",
       "2                            1.6817                      0.9609   \n",
       "3                            1.6817                      0.9609   \n",
       "4                            5.9782                      3.4162   \n",
       "...                             ...                         ...   \n",
       "3999                         5.3333                      3.1342   \n",
       "4000                         0.1958                      0.1120   \n",
       "4001                         1.6448                      0.9398   \n",
       "4002                         4.9360                      2.8438   \n",
       "4003                         4.3298                      2.4742   \n",
       "\n",
       "      total_travel_cost_shared_3p  cost_per_distance_drive_alone  \\\n",
       "0                          2.2856                       0.184799   \n",
       "1                          1.7807                       0.184803   \n",
       "2                          0.6726                       0.184802   \n",
       "3                          0.6726                       0.184802   \n",
       "4                          2.3913                       0.184798   \n",
       "...                           ...                            ...   \n",
       "3999                       2.1940                       0.184799   \n",
       "4000                       0.0784                       0.184717   \n",
       "4001                       0.6578                       0.184809   \n",
       "4002                       1.9907                       0.184800   \n",
       "4003                       1.7320                       0.184797   \n",
       "\n",
       "      cost_per_distance_shared_2  cost_per_distance_shared_3p  \n",
       "0                       0.105598                     0.073920  \n",
       "1                       0.105600                     0.073919  \n",
       "2                       0.105593                     0.073912  \n",
       "3                       0.105593                     0.073912  \n",
       "4                       0.105601                     0.073920  \n",
       "...                          ...                          ...  \n",
       "3999                    0.105600                     0.073922  \n",
       "4000                    0.105660                     0.073962  \n",
       "4001                    0.105596                     0.073910  \n",
       "4002                    0.105600                     0.073921  \n",
       "4003                    0.105600                     0.073922  \n",
       "\n",
       "[4004 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data_wide[bike_data_wide['availability_shared_3p']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of variables of interest from data_wide\n",
    "columns_wide = ['num_kids', 'household_size', 'num_cars',\n",
    "                'num_licensed_drivers', 'cross_bay',\n",
    "                'total_travel_time_drive_alone', 'total_travel_time_shared_2',\n",
    "                'total_travel_time_shared_3p', 'total_travel_time_wtw',\n",
    "                'total_travel_time_dtw', 'total_travel_time_wtd',\n",
    "                'total_travel_time_walk', 'total_travel_time_bike',\n",
    "                'total_travel_distance_drive_alone', 'total_travel_distance_shared_2',\n",
    "                'total_travel_distance_shared_3p', 'total_travel_distance_wtw',\n",
    "                'total_travel_distance_dtw', 'total_travel_distance_wtd',\n",
    "                'total_travel_distance_walk', 'total_travel_distance_bike',\n",
    "                'total_travel_cost_drive_alone', 'total_travel_cost_shared_2',\n",
    "                'total_travel_cost_shared_3p']\n",
    "\n",
    "bike_data_wide = bike_data_wide[columns_wide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the distributions to be used\n",
    "distributions = ['normal','alpha','beta','gamma','expon','gumbel']\n",
    "\n",
    "# Initial the FitDistribution object\n",
    "bike_data_fitter = FitDistribution(data=bike_data_wide,dists=distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nature of each variables whether discrete/categorical or continuous\n",
    "variable_type = {'num_kids': 'categorical',\n",
    "                 'household_size': 'categorical',\n",
    "                 'num_cars': 'discrete',\n",
    "                 'num_licensed_drivers': 'categorical',\n",
    "                 'cross_bay': 'categorical',\n",
    "                 'total_travel_time_drive_alone': 'continuous',\n",
    "                 'total_travel_time_shared_2': 'continuous',\n",
    "                 'total_travel_time_shared_3p': 'continuous',\n",
    "                 'total_travel_time_wtw': 'continuous',\n",
    "                 'total_travel_time_dtw': 'continuous',\n",
    "                 'total_travel_time_wtd': 'continuous',\n",
    "                 'total_travel_time_walk': 'continuous',\n",
    "                 'total_travel_time_bike': 'continuous',\n",
    "                 'total_travel_distance_drive_alone': 'continuous',\n",
    "                 'total_travel_distance_shared_2': 'continuous',\n",
    "                 'total_travel_distance_shared_3p': 'continuous',\n",
    "                 'total_travel_distance_wtw': 'continuous',\n",
    "                 'total_travel_distance_dtw': 'continuous',\n",
    "                 'total_travel_distance_wtd': 'continuous',\n",
    "                 'total_travel_distance_walk': 'continuous',\n",
    "                 'total_travel_distance_bike': 'continuous',\n",
    "                 'total_travel_cost_drive_alone': 'continuous',\n",
    "                 'total_travel_cost_shared_2': 'continuous',\n",
    "                 'total_travel_cost_shared_3p': 'continuous'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dataframe based on the estimated distributions\n",
    "sim_bike_data = bike_data_fitter.SimDf(size = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate variables - Based on Long Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindLongDataDist(data_long, \n",
    "                     alt_id_col,\n",
    "                     obs_id_col,\n",
    "                     alt_spec,\n",
    "                     alt_name_dic,\n",
    "                     ind_spec,\n",
    "                     trip_spec,\n",
    "                     var_types,\n",
    "                     cont_dists = None):\n",
    "    \n",
    "    params_dict = defaultdict(dict)\n",
    "    \n",
    "    # Code for Individual Specific Variables\n",
    "    for ind in ind_spec:\n",
    "        ind_var=pd.Series([(data_long.loc[data_long[obs_id_col]==x][ind].unique()[0]) for x in data_long[obs_id_col].unique()])\n",
    "        if  var_types[ind] == 'categorical':\n",
    "            if len(ind_var.unique()) == 1:\n",
    "                params_dict[ind]['distribution'] = 'constant'\n",
    "                params_dict[ind]['parameters'] = ind_var.unique()\n",
    "            else:\n",
    "                params_dict[ind]['distribution'] = 'categorical'\n",
    "                np_array_range = np.arange(ind_var.max()+1)\n",
    "                array_bincount = np.bincount(ind_var)\n",
    "                probs = array_bincount / len(ind_var)\n",
    "                params_dict[ind]['parameters'] = [np_array_range,\n",
    "                                                          probs]            \n",
    "        else:\n",
    "            if len(ind_var.unique()) == 1:\n",
    "                params_dict[ind]['distribution'] = 'constant'\n",
    "                params_dict[ind]['parameters'] = ind_var.unique()\n",
    "            else:\n",
    "                fitter_object = Fitter(data=ind_var,\n",
    "                                       distributions=cont_dists,\n",
    "                                       timeout=30)\n",
    "                fitter_object.fit()\n",
    "                BestDict = fitter_object.get_best()\n",
    "                params_dict[ind]['distribution'] = list(BestDict.items())[0][0]\n",
    "                params_dict[ind]['parameters'] = list(BestDict.items())[0][1]\n",
    "    \n",
    "    # Code for Alternative Specific Variables\n",
    "    \n",
    "    for alt in data_long[alt_id_col].unique():\n",
    "        mode_data = data_long.loc[data_long['mode_id']==alt]\n",
    "        for var in alt_spec:\n",
    "            if  var_types[var] == 'categorical':\n",
    "                if len(mode_data[var].unique()) == 1:\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['distribution'] = 'constant'\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['parameters'] = mode_data[var].unique()\n",
    "                else:\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['distribution'] = 'categorical'\n",
    "                    np_array_range = np.arange(mode_data[var].max()+1)\n",
    "                    array_bincount = np.bincount(mode_data[var])\n",
    "                    probs = array_bincount / len(mode_data[var])\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['parameters'] = [np_array_range,\n",
    "                                                              probs]            \n",
    "            else:\n",
    "                if len(mode_data[var].unique()) == 1:\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['distribution'] = 'constant'\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['parameters'] = mode_data[var].unique()\n",
    "                else:\n",
    "                    fitter_object = Fitter(data=mode_data[var],\n",
    "                                           distributions=cont_dists,\n",
    "                                           timeout=30)\n",
    "                    fitter_object.fit()\n",
    "                    BestDict = fitter_object.get_best()\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['distribution'] = list(BestDict.items())[0][0]\n",
    "                    params_dict[var+'_'+alt_name_dic[alt]]['parameters'] = list(BestDict.items())[0][1]\n",
    "    \n",
    "    # Trip Specific Variable (maybe combine with individual specific variables)\n",
    "    for var in trip_spec:\n",
    "        trip_var=pd.Series([(data_long.loc[data_long[obs_id_col]==x][var].unique()[0]) for x in data_long[obs_id_col].unique()])\n",
    "        if  var_types[var] == 'categorical':\n",
    "            if len(trip_var.unique()) == 1:\n",
    "                params_dict[var]['distribution'] = 'constant'\n",
    "                params_dict[var]['parameters'] = trip_var.unique()\n",
    "            else:\n",
    "                params_dict[var]['distribution'] = 'categorical'\n",
    "                np_array_range = np.arange(trip_var.max()+1)\n",
    "                array_bincount = np.bincount(trip_var)\n",
    "                probs = array_bincount / len(trip_var)\n",
    "                params_dict[var]['parameters'] = [np_array_range,\n",
    "                                                          probs]            \n",
    "        else:\n",
    "            if len(trip_var.unique()) == 1:\n",
    "                params_dict[var]['distribution'] = 'constant'\n",
    "                params_dict[var]['parameters'] = trip_var.unique()\n",
    "            else:\n",
    "                fitter_object = Fitter(data=trip_var,\n",
    "                                       distributions=cont_dists,\n",
    "                                       timeout=30)\n",
    "                fitter_object.fit()\n",
    "                BestDict = fitter_object.get_best()\n",
    "                params_dict[var]['distribution'] = list(BestDict.items())[0][0]\n",
    "                params_dict[var]['parameters'] = list(BestDict.items())[0][1]\n",
    "                \n",
    "    return params_dict\n",
    "\n",
    "\n",
    "def SimDf(params_dict, size=1000):\n",
    "        \"\"\"Funtion to simulate data of size N based on specified\n",
    "        distribution/parameters found by the fitter package.\n",
    "        Inputs:\n",
    "        -------\n",
    "        data: dataframe from which columns are to be taken\n",
    "        dist_params: the distribution parameters from find_dist_df\n",
    "        Outputs:\n",
    "        -------\n",
    "        DataFrame object with simulated data based on specified distributions\n",
    "        \"\"\"\n",
    "        Sim_Df = pd.DataFrame(columns=list(params_dict.keys()))\n",
    "        Sim_Df = Sim_Df.fillna(0)\n",
    "        for column in list(params_dict.keys()):\n",
    "            if params_dict[column]['distribution'] == 'categorical':\n",
    "                data_sim = np.random.choice(a=params_dict[column]['parameters'][0],\n",
    "                                            p=params_dict[column]['parameters'][1],\n",
    "                                            size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "            elif params_dict[column]['distribution'] == 'constant':\n",
    "                data_sim = params_dict[column]['parameters'][0]\n",
    "                Sim_Df[column] = data_sim\n",
    "            else:\n",
    "                dist = getattr(scipy.stats, params_dict[column]['distribution'])\n",
    "                data_sim = dist.rvs(*params_dict[column]['parameters'], size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "        return Sim_Df\n",
    "    \n",
    "\n",
    "def SimulateAvailability(data_long, sim_data, obs_id_col, alt_name_dict):\n",
    "    \n",
    "    series = pd.Series([])\n",
    "    for i,obs in zip(np.arange(len(data_long[obs_id_col].unique())), data_long[obs_id_col].unique()):\n",
    "        series[i] = data_long[data_long[obs_id_col]==obs].shape[0]\n",
    "\n",
    "    av_size = sim_data.shape[0]\n",
    "    alts_sim = np.random.choice(a=np.arange(series.max()+1),\n",
    "                                p=np.bincount(series)/len(series),\n",
    "                                size=av_size)\n",
    "\n",
    "    N = len(alt_name_dict)\n",
    "    \n",
    "    av_sim=[np.array([1] * K + [0]*(N-K)) for K in alts_sim]\n",
    "\n",
    "    for x in av_sim:\n",
    "        np.random.shuffle(x)\n",
    "\n",
    "    np.random.shuffle(av_sim)\n",
    "    AV_columns=[alt_name_dict[i]+'_AV' for i in alt_name_dict.keys()]\n",
    "    AV_Df = pd.DataFrame(av_sim, columns=AV_columns)\n",
    "    choice = [random.choice(np.nonzero(a==1)[0]) + 1 for a in np.array(AV_Df)]\n",
    "    choice_df = pd.DataFrame(choice, columns=['choice'])\n",
    "    Sim_DF_AV = pd.concat([sim_data, AV_Df, choice_df], axis = 1, sort=False)\n",
    "    return Sim_DF_AV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_id_col = 'observation_id'\n",
    "\n",
    "alternative_id_col = 'mode_id'\n",
    "\n",
    "variable_type = {'num_kids': 'categorical',\n",
    "                 'household_size': 'categorical',\n",
    "                 'num_cars': 'categorical',\n",
    "                 'num_licensed_drivers': 'categorical'}\n",
    "\n",
    "individual_specific_variables = ['num_kids','household_size',\n",
    "                                 'num_cars','num_licensed_drivers']\n",
    "\n",
    "alternative_specific_variables = ['total_travel_time','total_travel_distance','total_travel_cost']\n",
    "\n",
    "trip_specific_variables = ['cross_bay']\n",
    "\n",
    "alternative_name_dict = {1: 'drive_alone',\n",
    "                         2: 'shared_2',\n",
    "                         3: 'shared_3p',\n",
    "                         4: 'wtw',\n",
    "                         5: 'dtw',\n",
    "                         6: 'wtd',\n",
    "                         7: 'walk',\n",
    "                         8: 'bike'}\n",
    "\n",
    "variable_type = {'num_kids': 'categorical',\n",
    "                 'household_size': 'categorical',\n",
    "                 'num_cars': 'categorical',\n",
    "                 'num_licensed_drivers': 'categorical',\n",
    "                 'cross_bay': 'categorical',\n",
    "                 'total_travel_time': 'continuous',\n",
    "                 'total_travel_distance': 'continuous',\n",
    "                 'total_travel_cost': 'continuous'}\n",
    "\n",
    "distributions = ['normal','alpha','beta','gamma','expon','gumbel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.0007989652291582563)\n",
      "Fitted beta distribution with error=0.00021837510493444555)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2381: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  Lhat = muhat - Shat*mu\n",
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_continuous_distns.py:515: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted gamma distribution with error=0.00021215664843294874)\n",
      "Fitted expon distribution with error=0.00042675380208476757)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.014522128648725777)\n",
      "Fitted beta distribution with error=0.0011963782652540424)\n",
      "Fitted gamma distribution with error=0.0011394543473683448)\n",
      "Fitted expon distribution with error=0.002052652669300775)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.013034447497270776)\n",
      "Fitted beta distribution with error=0.04104766585766829)\n",
      "Fitted gamma distribution with error=0.03662007898297577)\n",
      "Fitted expon distribution with error=0.07921887555564106)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.001056930694286857)\n",
      "Fitted beta distribution with error=0.0002880878794523213)\n",
      "Fitted gamma distribution with error=0.00028798219056962133)\n",
      "Fitted expon distribution with error=0.0006139993763181574)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.014457810916552023)\n",
      "Fitted beta distribution with error=0.0012976882508515305)\n",
      "Fitted gamma distribution with error=0.0012552378475140624)\n",
      "Fitted expon distribution with error=0.0019967778289294194)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.04504063577126065)\n",
      "Fitted beta distribution with error=0.15781307177556403)\n",
      "Fitted gamma distribution with error=0.15841075884851374)\n",
      "Fitted expon distribution with error=0.25956064777904964)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.0010612734128178794)\n",
      "Fitted beta distribution with error=0.00023601477811189558)\n",
      "Fitted gamma distribution with error=0.00023611716873763347)\n",
      "Fitted expon distribution with error=0.0006076210852379661)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.014462601227138085)\n",
      "Fitted beta distribution with error=0.001276124018206852)\n",
      "Fitted gamma distribution with error=0.0012547975031013958)\n",
      "Fitted expon distribution with error=0.0020004181046601524)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.09325519048258353)\n",
      "Fitted beta distribution with error=0.2719576971221132)\n",
      "Fitted gamma distribution with error=0.2684643698148782)\n",
      "Fitted expon distribution with error=0.4484867698126394)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.00010782141835446614)\n",
      "Fitted beta distribution with error=0.00011146390130275948)\n",
      "Fitted gamma distribution with error=0.00010902380039568413)\n",
      "Fitted expon distribution with error=0.0006821775284529087)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=8.394020014580313)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last five Jacobian evaluations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted beta distribution with error=8.724425966292245)\n",
      "Fitted gamma distribution with error=8.724370722136563)\n",
      "Fitted expon distribution with error=9.1690513221318)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=6.672556141363111e-05)\n",
      "Fitted beta distribution with error=6.196777802352273e-05)\n",
      "Fitted gamma distribution with error=6.08535018564024e-05)\n",
      "Fitted expon distribution with error=0.0007188034183935458)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=8.324919501617495)\n",
      "Fitted beta distribution with error=9.381940852860888)\n",
      "Fitted gamma distribution with error=8.638629330672966)\n",
      "Fitted expon distribution with error=9.271523141699383)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=8.054952402098987e-05)\n",
      "Fitted beta distribution with error=8.156641381917802e-05)\n",
      "Fitted gamma distribution with error=8.048390439269993e-05)\n",
      "Fitted expon distribution with error=0.0008900680532886661)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=8.770907888528171)\n",
      "Fitted beta distribution with error=9.796625940589463)\n",
      "Fitted gamma distribution with error=9.081385466834893)\n",
      "Fitted expon distribution with error=9.667837356880147)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=3.710751949856986e-05)\n",
      "Fitted beta distribution with error=5.925127101230748e-06)\n",
      "Fitted gamma distribution with error=5.804430139130399e-06)\n",
      "Fitted expon distribution with error=8.673334653358734e-06)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.0008972367532526685)\n",
      "Fitted beta distribution with error=0.002377025832720183)\n",
      "Fitted gamma distribution with error=0.002275034836025737)\n",
      "Fitted expon distribution with error=0.003469333861343498)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.0005543487080009017)\n",
      "Fitted beta distribution with error=9.899959495894452e-05)\n",
      "Fitted gamma distribution with error=7.59436705777334e-05)\n",
      "Fitted expon distribution with error=0.000167136671750175)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n",
      "SKIPPED normal distribution (taking more than 30 seconds)\n",
      "Fitted alpha distribution with error=0.0007221359033952726)\n",
      "Fitted beta distribution with error=0.0024566904071273085)\n",
      "Fitted gamma distribution with error=0.0024407152169873807)\n",
      "Fitted expon distribution with error=0.004178416793754377)\n",
      "SKIPPED gumbel distribution (taking more than 30 seconds)\n"
     ]
    }
   ],
   "source": [
    "bike_data_params = FindLongDataDist(data_long=bike_data_long,\n",
    "                                   alt_id_col=alternative_id_col,\n",
    "                                   obs_id_col=observation_id_col,\n",
    "                                   alt_spec=alternative_specific_variables,\n",
    "                                   alt_name_dic=alternative_name_dict,\n",
    "                                   ind_spec=individual_specific_variables,\n",
    "                                   trip_spec=trip_specific_variables,\n",
    "                                   var_types=variable_type,\n",
    "                                   cont_dists=distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = SimDf(params_dict=bike_data_params,size = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_kids</th>\n",
       "      <th>household_size</th>\n",
       "      <th>num_cars</th>\n",
       "      <th>num_licensed_drivers</th>\n",
       "      <th>total_travel_time_drive_alone</th>\n",
       "      <th>total_travel_distance_drive_alone</th>\n",
       "      <th>total_travel_cost_drive_alone</th>\n",
       "      <th>total_travel_time_shared_2</th>\n",
       "      <th>total_travel_distance_shared_2</th>\n",
       "      <th>total_travel_cost_shared_2</th>\n",
       "      <th>...</th>\n",
       "      <th>total_travel_time_wtd</th>\n",
       "      <th>total_travel_distance_wtd</th>\n",
       "      <th>total_travel_cost_wtd</th>\n",
       "      <th>total_travel_time_walk</th>\n",
       "      <th>total_travel_distance_walk</th>\n",
       "      <th>total_travel_cost_walk</th>\n",
       "      <th>total_travel_time_bike</th>\n",
       "      <th>total_travel_distance_bike</th>\n",
       "      <th>total_travel_cost_bike</th>\n",
       "      <th>cross_bay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.465759</td>\n",
       "      <td>5.293858</td>\n",
       "      <td>9.121442</td>\n",
       "      <td>30.138424</td>\n",
       "      <td>1.065751</td>\n",
       "      <td>0.902807</td>\n",
       "      <td>...</td>\n",
       "      <td>56.507878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.223299</td>\n",
       "      <td>6.073122</td>\n",
       "      <td>7.478569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.185408</td>\n",
       "      <td>8.533136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.447209</td>\n",
       "      <td>5.005379</td>\n",
       "      <td>1.836917</td>\n",
       "      <td>19.517252</td>\n",
       "      <td>4.309764</td>\n",
       "      <td>1.690908</td>\n",
       "      <td>...</td>\n",
       "      <td>35.225908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.325932</td>\n",
       "      <td>37.891090</td>\n",
       "      <td>20.032938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.275359</td>\n",
       "      <td>2.113692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.820240</td>\n",
       "      <td>20.679317</td>\n",
       "      <td>2.898893</td>\n",
       "      <td>20.795035</td>\n",
       "      <td>12.205455</td>\n",
       "      <td>25.321525</td>\n",
       "      <td>...</td>\n",
       "      <td>153.004399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.525199</td>\n",
       "      <td>775.210947</td>\n",
       "      <td>6.850928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.194379</td>\n",
       "      <td>41.810972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.997781</td>\n",
       "      <td>0.961277</td>\n",
       "      <td>10.734576</td>\n",
       "      <td>60.354784</td>\n",
       "      <td>11.491783</td>\n",
       "      <td>0.627537</td>\n",
       "      <td>...</td>\n",
       "      <td>72.494226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.033902</td>\n",
       "      <td>342.766027</td>\n",
       "      <td>2.358583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.495673</td>\n",
       "      <td>6.396019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.166375</td>\n",
       "      <td>20.185367</td>\n",
       "      <td>2.181793</td>\n",
       "      <td>15.940565</td>\n",
       "      <td>2.750518</td>\n",
       "      <td>0.842715</td>\n",
       "      <td>...</td>\n",
       "      <td>22.195299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.979798</td>\n",
       "      <td>71.330840</td>\n",
       "      <td>11.373233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.864022</td>\n",
       "      <td>3.043038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_kids  household_size  num_cars  num_licensed_drivers  \\\n",
       "0         2             2.0       2.0                   3.0   \n",
       "1         5             3.0       1.0                   2.0   \n",
       "2         0             5.0       0.0                   2.0   \n",
       "3         1             5.0       0.0                   2.0   \n",
       "4         2             7.0       3.0                   3.0   \n",
       "\n",
       "   total_travel_time_drive_alone  total_travel_distance_drive_alone  \\\n",
       "0                       7.465759                           5.293858   \n",
       "1                      16.447209                           5.005379   \n",
       "2                      24.820240                          20.679317   \n",
       "3                      10.997781                           0.961277   \n",
       "4                      44.166375                          20.185367   \n",
       "\n",
       "   total_travel_cost_drive_alone  total_travel_time_shared_2  \\\n",
       "0                       9.121442                   30.138424   \n",
       "1                       1.836917                   19.517252   \n",
       "2                       2.898893                   20.795035   \n",
       "3                      10.734576                   60.354784   \n",
       "4                       2.181793                   15.940565   \n",
       "\n",
       "   total_travel_distance_shared_2  total_travel_cost_shared_2  ...  \\\n",
       "0                        1.065751                    0.902807  ...   \n",
       "1                        4.309764                    1.690908  ...   \n",
       "2                       12.205455                   25.321525  ...   \n",
       "3                       11.491783                    0.627537  ...   \n",
       "4                        2.750518                    0.842715  ...   \n",
       "\n",
       "   total_travel_time_wtd  total_travel_distance_wtd  total_travel_cost_wtd  \\\n",
       "0              56.507878                        0.0               5.223299   \n",
       "1              35.225908                        0.0               3.325932   \n",
       "2             153.004399                        0.0               2.525199   \n",
       "3              72.494226                        0.0               7.033902   \n",
       "4              22.195299                        0.0               6.979798   \n",
       "\n",
       "   total_travel_time_walk  total_travel_distance_walk  total_travel_cost_walk  \\\n",
       "0                6.073122                    7.478569                     0.0   \n",
       "1               37.891090                   20.032938                     0.0   \n",
       "2              775.210947                    6.850928                     0.0   \n",
       "3              342.766027                    2.358583                     0.0   \n",
       "4               71.330840                   11.373233                     0.0   \n",
       "\n",
       "   total_travel_time_bike  total_travel_distance_bike  total_travel_cost_bike  \\\n",
       "0               87.185408                    8.533136                     0.0   \n",
       "1                6.275359                    2.113692                     0.0   \n",
       "2               27.194379                   41.810972                     0.0   \n",
       "3               21.495673                    6.396019                     0.0   \n",
       "4               58.864022                    3.043038                     0.0   \n",
       "\n",
       "   cross_bay  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_sim_data = SimulateAvailability(bike_data_long, sim_data=sim_data, obs_id_col=observation_id_col, alt_name_dict=alternative_name_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Choices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Simulated Data from Wide to Long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_kids', 'household_size', 'num_cars', 'num_licensed_drivers',\n",
       "       'total_travel_time_drive_alone', 'total_travel_distance_drive_alone',\n",
       "       'total_travel_cost_drive_alone', 'total_travel_time_shared_2',\n",
       "       'total_travel_distance_shared_2', 'total_travel_cost_shared_2',\n",
       "       'total_travel_time_shared_3p', 'total_travel_distance_shared_3p',\n",
       "       'total_travel_cost_shared_3p', 'total_travel_time_wtw',\n",
       "       'total_travel_distance_wtw', 'total_travel_cost_wtw',\n",
       "       'total_travel_time_dtw', 'total_travel_distance_dtw',\n",
       "       'total_travel_cost_dtw', 'total_travel_time_wtd',\n",
       "       'total_travel_distance_wtd', 'total_travel_cost_wtd',\n",
       "       'total_travel_time_walk', 'total_travel_distance_walk',\n",
       "       'total_travel_cost_walk', 'total_travel_time_bike',\n",
       "       'total_travel_distance_bike', 'total_travel_cost_bike', 'cross_bay',\n",
       "       'drive_alone_AV', 'shared_2_AV', 'shared_3p_AV', 'wtw_AV', 'dtw_AV',\n",
       "       'wtd_AV', 'walk_AV', 'bike_AV', 'choice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_sim_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_variables = ['num_kids','household_size',\n",
    "                 'num_cars','num_licensed_drivers','cross_bay']\n",
    "\n",
    "\n",
    "alt_varying_variables = {u'total_travel_time': dict([(1, 'total_travel_time_drive_alone'),\n",
    "                                                     (2, 'total_travel_time_shared_2'),\n",
    "                                                     (3, 'total_travel_time_shared_3p'),\n",
    "                                                    (4, 'total_travel_time_wtw'),\n",
    "                                                    (5, 'total_travel_time_dtw'),\n",
    "                                                    (6, 'total_travel_time_wtd'),\n",
    "                                                    (7, 'total_travel_time_walk'),\n",
    "                                                    (8, 'total_travel_time_bike')]),\n",
    "                          u'total_travel_cost': dict([(1, 'total_travel_cost_drive_alone'),\n",
    "                                                     (2, 'total_travel_cost_shared_2'),\n",
    "                                                     (3, 'total_travel_cost_shared_3p'),\n",
    "                                                    (4, 'total_travel_cost_wtw'),\n",
    "                                                    (5, 'total_travel_cost_dtw'),\n",
    "                                                    (6, 'total_travel_cost_wtd'),\n",
    "                                                    (7, 'total_travel_cost_walk'),\n",
    "                                                    (8, 'total_travel_cost_bike')]),\n",
    "                         u'total_travel_distance': dict([(1, 'total_travel_distance_drive_alone'),\n",
    "                                                     (2, 'total_travel_distance_shared_2'),\n",
    "                                                     (3, 'total_travel_distance_shared_3p'),\n",
    "                                                    (4, 'total_travel_distance_wtw'),\n",
    "                                                    (5, 'total_travel_distance_dtw'),\n",
    "                                                    (6, 'total_travel_distance_wtd'),\n",
    "                                                    (7, 'total_travel_distance_walk'),\n",
    "                                                    (8, 'total_travel_distance_bike')]),\n",
    "                        }\n",
    "\n",
    "\n",
    "availability_variables = {1: 'drive_alone_AV',\n",
    "                         2: 'shared_2_AV',\n",
    "                         3: 'shared_3p_AV',\n",
    "                         4: 'wtw_AV',\n",
    "                         5: 'dtw_AV',\n",
    "                         6: 'wtd_AV',\n",
    "                         7: 'walk_AV',\n",
    "                         8: 'bike_AV'}\n",
    "\n",
    "##########\n",
    "# Determine the columns for: alternative ids, the observation ids and the choice\n",
    "##########\n",
    "# The 'custom_alt_id' is the name of a column to be created in the long-format data\n",
    "# It will identify the alternative associated with each row.\n",
    "custom_alt_id = \"mode_id\"\n",
    "\n",
    "# Create a custom id column that ignores the fact that this is a \n",
    "# panel/repeated-observations dataset. Note the +1 ensures the id's start at one.\n",
    "obs_id_column = \"observation_id\"\n",
    "wide_sim_data[obs_id_column] = np.arange(wide_sim_data.shape[0],\n",
    "                                            dtype=int) + 1\n",
    "\n",
    "\n",
    "# Create an empty choice column\n",
    "choice_column = \"choice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Long Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_sim_data = pl.convert_wide_to_long(wide_sim_data, \n",
    "                                           ind_variables, \n",
    "                                           alt_varying_variables, \n",
    "                                           availability_variables, \n",
    "                                           obs_id_column, \n",
    "                                           choice_column,\n",
    "                                           new_alt_id_name=custom_alt_id)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
