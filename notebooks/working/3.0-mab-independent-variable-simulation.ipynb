{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from fitter import Fitter\n",
    "#import attr\n",
    "from collections import defaultdict, OrderedDict\n",
    "import pylogit as pl\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Fitting Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitDistribution(object):\n",
    "    \"\"\"Fit and simulate data to known distributions.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    - data: array-like or dataframe.\n",
    "    - dists: list.\n",
    "        This parameter contains a list of distributions to be explored.\n",
    "        When None, every available distribution on scipy is explored.\n",
    "    - bins: int. \n",
    "        Numbers of bins to be used for the cumulative histogram. This has\n",
    "        an impact on the quality of the fit.\n",
    "    - timeout: int. \n",
    "        Maximum time for a given distribution. If timeout is reached, \n",
    "        the distribution is skipped.\n",
    "        \"\"\"\n",
    "    def __init__(self, data, dists=None, timeout=30, verbose=False, bins=100):\n",
    "        self.data = data\n",
    "        #self.var_types = var_types\n",
    "        self.dists = dists\n",
    "        self.timeout = timeout\n",
    "        self.verbose = verbose\n",
    "        self.bins = bins\n",
    "        self.ArrayDistDict = defaultdict()\n",
    "        self.params_dict = defaultdict(dict)\n",
    "\n",
    "    def FindArrayDist(self, cat_var):\n",
    "        \"\"\"Function to extract the best distribution for a specified array.\n",
    "        Uses the fit method from the Fitter module in the fitter library\n",
    "        Inputs:\n",
    "        -------\n",
    "        - cat_var: boolean\n",
    "            Boolean to signify whether the variable to be simulated\n",
    "            is discrete/categorical or continuous.\n",
    "        \n",
    "        Outputs:\n",
    "        -------\n",
    "        By default, the function returns a dictionary with best distribution name\n",
    "        and parameters associated with it. If a number of distributions\n",
    "        was specified, the function returns a pandas DataFrame with\n",
    "        the N best distributions, along with a plot showing all of them.\"\"\"\n",
    "        self.ArrayDistDict = dict()\n",
    "        if  cat_var == True:\n",
    "            self.ArrayDistDict['distribution'] = 'categorical'\n",
    "            np_array_range = np.arange(self.data.max()+1)\n",
    "            array_bincount = np.bincount(self.data)\n",
    "            probs = array_bincount / len(self.data)\n",
    "            \n",
    "            self.ArrayDistDict['parameters'] = [np_array_range,\n",
    "                                                probs]            \n",
    "        else:\n",
    "            fitter_object = Fitter(data=self.data,\n",
    "                                   distributions=self.dists,\n",
    "                                   timeout=self.timeout)\n",
    "            fitter_object.fit()\n",
    "            BestDict = fitter_object.get_best()\n",
    "            self.ArrayDistDict['distribution'] = list(BestDict.items())[0][0]\n",
    "            self.ArrayDistDict['parameters'] = list(BestDict.items())[0][1]\n",
    "        return self.ArrayDistDict\n",
    "    \n",
    "    def SimArray(self, size=100):\n",
    "        \"\"\"Function to simulate data for an array based on the best fitted\n",
    "        distribution.\n",
    "        Input:\n",
    "        -----\n",
    "        - size : int\n",
    "                size of the array to be simulated.\n",
    "        Outputs:\n",
    "        -------\n",
    "        Simulated array based on the best fit distribution.\"\"\"\n",
    "        if self.ArrayDistDict['distribution'] == 'categorical':\n",
    "            Sim_Array = np.random.choice(a=self.ArrayDistDict['parameters'][0],\n",
    "                                         p=self.ArrayDistDict['parameters'][1],\n",
    "                                         size=size)\n",
    "        else:\n",
    "            dist = getattr(scipy.stats, self.ArrayDistDict['distribution'])\n",
    "            Sim_Array = dist.rvs(*self.ArrayDistDict['parameters'], size=size)\n",
    "        return Sim_Array\n",
    "    \n",
    "    def FindDfDist(self, var_types):\n",
    "        \"\"\"Function to extract the best distribution from a specified dataframe.\n",
    "        Uses the function find_dist, which in turn uses the fit method from the\n",
    "        Fitter module in the fitter library\n",
    "        Inputs:\n",
    "        -------\n",
    "        - var_types: dictionary\n",
    "            Dictionary with keys as column names for dataset variables, the value\n",
    "            of each key is a string showing whether the variable is discrete/cat\n",
    "            or continuous.\n",
    "\n",
    "        Outputs:\n",
    "        -------\n",
    "        *FOR NOW*, the function returns a dictionary showing the best distribution\n",
    "        name for each array in the dataframe and parameters associated with it.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        for column in list(self.data.columns):\n",
    "            if  var_types[column] == 'categorical':\n",
    "                self.params_dict[column]['distribution'] = 'categorical'\n",
    "                np_array_range = np.arange(self.data[column].max()+1)\n",
    "                array_bincount = np.bincount(self.data[column])\n",
    "                probs = array_bincount / len(self.data[column])\n",
    "                self.params_dict[column]['parameters'] = [np_array_range,\n",
    "                                                          probs]            \n",
    "            else:\n",
    "                fitter_object = Fitter(data=self.data[column],\n",
    "                                       distributions=self.dists,\n",
    "                                       timeout=self.timeout)\n",
    "                fitter_object.fit()\n",
    "                BestDict = fitter_object.get_best()\n",
    "                self.params_dict[column]['distribution'] = list(BestDict.items())[0][0]\n",
    "                self.params_dict[column]['parameters'] = list(BestDict.items())[0][1]\n",
    "        return self.params_dict\n",
    "\n",
    "    def SimDf(self, size=1000):\n",
    "        \"\"\"Funtion to simulate data of size N based on specified\n",
    "        distribution/parameters found by the fitter package.\n",
    "        Inputs:\n",
    "        -------\n",
    "        data: dataframe from which columns are to be taken\n",
    "        dist_params: the distribution parameters from find_dist_df\n",
    "        Outputs:\n",
    "        -------\n",
    "        DataFrame object with simulated data based on specified distributions\n",
    "        \"\"\"\n",
    "        Sim_Df = pd.DataFrame(columns=list(self.params_dict.keys()))\n",
    "        Sim_Df = Sim_Df.fillna(0)\n",
    "        for column in list(self.params_dict.keys()):\n",
    "            if self.params_dict[column]['distribution'] == 'categorical':\n",
    "                data_sim = np.random.choice(a=self.params_dict[column]['parameters'][0],\n",
    "                                            p=self.params_dict[column]['parameters'][1],\n",
    "                                            size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "            else:\n",
    "                dist = getattr(scipy.stats, self.params_dict[column]['distribution'])\n",
    "                data_sim = dist.rvs(*self.params_dict[column]['parameters'], size=size)\n",
    "                Sim_Df[column] = data_sim\n",
    "        return Sim_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to calculate probabilities for each alternative **(to be replaced by functions from the choice_tools module in pylogit)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept_to_df(df_long, specification_dict):\n",
    "    \n",
    "    if (\"intercept\" in specification_dict \n",
    "        and \"intercept\" not in df_long.columns):\n",
    "        df_long[\"intercept\"] = 1\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_design_matrix(df_long, specification_dict,\n",
    "                         names_dict, alternative_id_col):\n",
    "    \n",
    "    add_intercept_to_df(df_long,specification_dict)\n",
    "    \n",
    "    columns = []\n",
    "    for col in specification_dict:\n",
    "        for group in specification_dict[col]:\n",
    "            if type(group) == list:\n",
    "                columns.append(df_long[alternative_id_col].isin(group)\n",
    "                               *df_long[col])\n",
    "            else:\n",
    "                columns.append((df_long[alternative_id_col]==group)\n",
    "                               *df_long[col])\n",
    "    \n",
    "    design_matrix = np.stack(columns,axis = 1)\n",
    "    \n",
    "    var_names = []\n",
    "    for variable in names_dict:\n",
    "        for name in names_dict[variable]:\n",
    "            var_names.append(name)\n",
    "    \n",
    "    return design_matrix, var_names\n",
    "\n",
    "\n",
    "def calculate_utilities(betas, design_matrix):\n",
    "    \n",
    "    limit_max = 700\n",
    "    limit_min = -700 \n",
    "    \n",
    "    utility = design_matrix.dot(betas)\n",
    "    utility[utility>limit_max] = limit_max\n",
    "    utility[utility<limit_min] = limit_min\n",
    "    \n",
    "    utilities = np.exp(utility)\n",
    "    \n",
    "    return utilities\n",
    "\n",
    "\n",
    "def create_mapping_matrix(df_long, observation_id_col):\n",
    "    row_to_col_matrix = pd.get_dummies(df_long[observation_id_col]).values\n",
    "#     row_to_col_matrix = (df_long[observation_id_col].values[:,None] == \n",
    "#                          np.sort(df_long[observation_id_col].unique())[None,:]).astype(int) \n",
    "    sparse_row_to_col_matrix = sparse.csr_matrix(row_to_col_matrix)\n",
    "    \n",
    "    mapping_matrix = sparse_row_to_col_matrix.dot(sparse_row_to_col_matrix.T)\n",
    "    \n",
    "    return mapping_matrix\n",
    "\n",
    "\n",
    "def calculate_probabilities(betas,design_matrix, mapping_matrix):\n",
    "    \n",
    "    utilities = calculate_utilities(betas, design_matrix)\n",
    "    denominator = mapping_matrix.dot(utilities)\n",
    "    probabilities = utilities/denominator\n",
    "    probabilities[probabilities==0] = 1e-300\n",
    "    \n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to simulate choices based on long data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimulateChoices(data, alt_id_col, obs_id_col, number_alts, spec_dic, names_dic, init_betas):\n",
    "\n",
    "# This commented out block is to extend the capabilities of the function from simulating choices\n",
    "# only based on long data to wide data. The logic is built out completely, all we need is to \n",
    "# refactor it and adjust the parameters in the function definition.\n",
    "#     choice_var = 'choice'\n",
    "#     custom_alt_id = \"alternative_id\"\n",
    "#     obs_id_column = \"custom_id\"\n",
    "\n",
    "#     # Adding a Choice Variable Column\n",
    "#     data[choice_var] = np.random.randint(1, high=number_alts+1, size=data.shape[0])\n",
    "#     availability_variables = dict()\n",
    "\n",
    "#     # Adding availability variables and specifying alternative availability numbers\n",
    "#     for alt in np.arange(1, number_alts+1, 1):\n",
    "#         data['AV_' + str(alt)] = 1\n",
    "#         availability_variables[alt] = 'AV_' + str(alt)\n",
    "\n",
    "#     # Specifying the Individual Variables\n",
    "#     ind_variables = ind_variables\n",
    "\n",
    "#     alt_varying_variables = alt_var_vars\n",
    "#     # Specifying the column heading for the alternative id column in the\n",
    "#     # long format dataset\n",
    "#     custom_alt_id = \"alternative_id\"\n",
    "#     obs_id_column = \"custom_id\"\n",
    "#     sample_data[obs_id_column] = np.arange(sample_data.shape[0],\n",
    "#                                            dtype=int) + 1\n",
    "\n",
    "#     # Create a variable recording the choice column\n",
    "\n",
    "#     long_data = pl.convert_wide_to_long(wide_data=sample_data,\n",
    "#                                         ind_vars=ind_variables,\n",
    "#                                         alt_specific_vars=alt_varying_variables,\n",
    "#                                         availability_vars=availability_variables,\n",
    "#                                         obs_id_col=obs_id_column,\n",
    "#                                         choice_col=choice_var,\n",
    "#                                         new_alt_id_name=custom_alt_id)\n",
    "    sim_choice_var = 'sim_choice'\n",
    "    # Functions to generate the probabilities for each alternative\n",
    "\n",
    "    long_data = data\n",
    "\n",
    "    design_matrix, names = create_design_matrix(df_long=long_data,\n",
    "                                                specification_dict=mnl_specification,\n",
    "                                                names_dict=mnl_names,\n",
    "                                                alternative_id_col=alt_id_col)\n",
    "    mapping_matrix = create_mapping_matrix(df_long=long_data,\n",
    "                                           observation_id_col=obs_id_col)\n",
    "    probabilities = calculate_probabilities(betas=initial_betas,\n",
    "                                            design_matrix=design_matrix,\n",
    "                                            mapping_matrix=mapping_matrix)\n",
    "\n",
    "    data['probabilities'] = probabilities\n",
    "    data['cum_sum'] = 0\n",
    "    data['sim_choice'] = 0\n",
    "\n",
    "    for observation in data['observation_id'].unique():\n",
    "        probs_sum = data[data.observation_id==observation]['probabilities'].cumsum()\n",
    "        data.loc[data['observation_id']==observation,'cum_sum'] = probs_sum\n",
    "\n",
    "    observation_id_list = list(data.observation_id.unique())\n",
    "    u_random = np.random.uniform(size = len(data['observation_id'].unique()))\n",
    "\n",
    "    for u,obs in zip(u_random,observation_id_list):\n",
    "        data_sample = data[data['observation_id']==obs]\n",
    "        sorted_list = sorted(list(data_sample['mode_id'].unique()))\n",
    "        choices = dict.fromkeys(sorted_list, 0)\n",
    "        for alt in sorted_list:   \n",
    "            choices[alt] = np.where(u<=data_sample[data_sample['mode_id']==alt]['cum_sum'], 1, 0).item()\n",
    "            if choices[alt] == 1:\n",
    "                break\n",
    "        data.loc[data.observation_id==obs,'sim_choice'] = data['mode_id'].map(choices)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using bike data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the path to the long format data for the multinomial choice model\n",
    "PATH = '/Users/mobouzaghrane/Documents/GitHub/tr_b_causal_2020/data/raw/spring_2016_all_bay_area_long_format_plus_cross_bay_col.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of bike_data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['household_id', 'person_id', 'tour_id', 'observation_id', 'mode_id',\n",
       "       'choice', 'tour_origin_taz', 'primary_dest_taz', 'total_travel_time',\n",
       "       'total_travel_cost', 'total_travel_distance', 'age', 'household_size',\n",
       "       'household_income', 'household_income_values', 'transit_subsidy',\n",
       "       'transit_subsidy_amount', 'num_cars', 'num_licensed_drivers',\n",
       "       'cross_bay', 'oakland_and_berkeley', 'survey_id', 'gender',\n",
       "       'non_relative_flag', 'num_pre_school', 'num_school_aged', 'married',\n",
       "       'parent', 'income_category_1', 'income_category_2', 'income_category_3',\n",
       "       'income_category_4', 'income_category_5', 'income_category_6',\n",
       "       'income_category_7', 'income_category_8', 'income_category_9',\n",
       "       'income_category_10', 'income_unknown', 'ln_drive_cost',\n",
       "       'ln_drive_cost_sq', 'total_travel_time_10x', 'total_travel_time_tenth',\n",
       "       'high_income', 'medium_income', 'low_income', 'high_income_cost',\n",
       "       'medium_income_cost', 'low_income_cost', 'unknown_income_cost',\n",
       "       'high_income_ln_cost', 'medium_income_ln_cost', 'low_income_ln_cost',\n",
       "       'unknown_income_ln_cost', 'cars_per_licensed_drivers', 'num_kids',\n",
       "       'family_in_household', 'married_woman', 'cost_per_distance',\n",
       "       'intercept', 'cost_per_distance_10$_per_mi',\n",
       "       'total_travel_time_tenth_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from the specified PATH\n",
    "bike_data = pd.read_csv(PATH)\n",
    "\n",
    "# If in previous work we accidentally saved the index with the dataframe\n",
    "# remove the old index from the data\n",
    "if \"Unnamed: 0\" in bike_data.columns:\n",
    "    del bike_data[\"Unnamed: 0\"]\n",
    "    \n",
    "print(\"The columns of bike_data are:\")\n",
    "bike_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drive Alone           0.428322\n",
       "Shared Ride 2         0.158841\n",
       "Shared Ride 3+        0.139860\n",
       "Walk-Transit-Walk     0.103397\n",
       "Drive-Transit-Walk    0.015485\n",
       "Walk-Transit-Drive    0.013237\n",
       "Walk                  0.094406\n",
       "Bike                  0.046454\n",
       "Name: Mode Shares, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the mode shares in the data set\n",
    "alt_id_to_mode_name = {1: \"Drive Alone\",\n",
    "                       2: \"Shared Ride 2\",\n",
    "                       3: \"Shared Ride 3+\",\n",
    "                       4: \"Walk-Transit-Walk\",\n",
    "                       5: \"Drive-Transit-Walk\",\n",
    "                       6: \"Walk-Transit-Drive\",\n",
    "                       7: \"Walk\",\n",
    "                       8: \"Bike\"}\n",
    "\n",
    "mode_counts = bike_data.loc[bike_data.choice==1,\n",
    "                            \"mode_id\"].value_counts().loc[range(1, 9)]\n",
    "\n",
    "mode_shares = mode_counts / bike_data.observation_id.max()\n",
    "mode_shares.index = [alt_id_to_mode_name[x] for x in mode_shares.index.values]\n",
    "mode_shares.name = \"Mode Shares\"\n",
    "mode_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL Model Specification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my specification and variable names for the basic MNL model\n",
    "# NOTE: - Keys should be variables within the long format dataframe.\n",
    "#         The sole exception to this is the \"intercept\" key.\n",
    "#       - For the specification dictionary, the values should be lists\n",
    "#         or lists of lists. Within a list, or within the inner-most\n",
    "#         list should be the alternative ID's of the alternative whose\n",
    "#         utility specification the explanatory variable is entering.\n",
    "\n",
    "mnl_specification = OrderedDict()\n",
    "mnl_names = OrderedDict()\n",
    "\n",
    "mnl_specification[\"intercept\"] = [2, 3, 4, 5, 6, 7, 8]\n",
    "mnl_names[\"intercept\"] = ['ASC Shared Ride: 2',\n",
    "                          'ASC Shared Ride: 3+',\n",
    "                          'ASC Walk-Transit-Walk',\n",
    "                          'ASC Drive-Transit-Walk',\n",
    "                          'ASC Walk-Transit-Drive',\n",
    "                          'ASC Walk',\n",
    "                          'ASC Bike']\n",
    "\n",
    "mnl_specification[\"total_travel_time\"] = [[1, 2, 3], [4, 5, 6]]\n",
    "mnl_names[\"total_travel_time\"] = ['Travel Time, units:min (All Auto Modes)',\n",
    "                                  'Travel Time, units:min (All Transit Modes)']\n",
    "\n",
    "mnl_specification[\"total_travel_cost\"] = [[4, 5, 6]]\n",
    "mnl_names[\"total_travel_cost\"] = ['Travel Cost, units:$ (All Transit Modes)']\n",
    "\n",
    "mnl_specification[\"cost_per_distance\"] = [1, 2, 3]\n",
    "mnl_names[\"cost_per_distance\"] = [\"Travel Cost per Distance, units:$/mi (Drive Alone)\",\n",
    "                                  \"Travel Cost per Distance, units:$/mi (SharedRide-2)\",\n",
    "                                  \"Travel Cost per Distance, units:$/mi (SharedRide-3+)\"]\n",
    "\n",
    "mnl_specification[\"cars_per_licensed_drivers\"] = [[1, 2, 3]]\n",
    "mnl_names[\"cars_per_licensed_drivers\"] = [\"Autos per licensed drivers (All Auto Modes)\"]\n",
    "\n",
    "mnl_specification[\"total_travel_distance\"] = [7, 8]\n",
    "mnl_names[\"total_travel_distance\"] = ['Travel Distance, units:mi (Walk)',\n",
    "                                      'Travel Distance, units:mi (Bike)']\n",
    "\n",
    "# mnl_specification[\"cross_bay\"] = [[2, 3], [4, 5, 6]]\n",
    "# mnl_names[\"cross_bay\"] = [\"Cross-Bay Tour (Shared Ride 2 & 3+)\",\n",
    "#                           \"Cross-Bay Tour (All Transit Modes)\"]\n",
    "mnl_specification[\"cross_bay\"] = [[2, 3]]\n",
    "mnl_names[\"cross_bay\"] = [\"Cross-Bay Tour (Shared Ride 2 & 3+)\"]\n",
    "\n",
    "mnl_specification[\"household_size\"] = [[2, 3]]\n",
    "mnl_names[\"household_size\"] = ['Household Size (Shared Ride 2 & 3+)']\n",
    "\n",
    "mnl_specification[\"num_kids\"] = [[2, 3]]\n",
    "mnl_names[\"num_kids\"] = [\"Number of Kids in Household (Shared Ride 2 & 3+)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -7,599.7019\n",
      "Initial Log-likelihood: -7,599.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/pylogit/choice_tools.py:703: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  design_matrix = np.hstack((x[:, None] for x in independent_vars))\n",
      "/Users/mobouzaghrane/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py:505: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.23 seconds.\n",
      "Final log-likelihood: -5,073.4276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multinomial Logit Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>choice</td>          <th>  No. Observations:  </th>    <td>4,004</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>         <td>Multinomial Logit Model</td> <th>  Df Residuals:      </th>    <td>3,985</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>     <td>19</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Mar 2020</td>     <th>  Pseudo R-squ.:     </th>    <td>0.332</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:02:51</td>         <th>  Pseudo R-bar-squ.: </th>    <td>0.330</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AIC:</th>                 <td>10,184.855</td>        <th>  Log-Likelihood:    </th> <td>-5,073.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIC:</th>                 <td>10,304.461</td>        <th>  LL-Null:           </th> <td>-7,599.702</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                            <td></td>                              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Shared Ride: 2</th>                                   <td>   -1.0097</td> <td>    0.486</td> <td>   -2.079</td> <td> 0.038</td> <td>   -1.962</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Shared Ride: 3+</th>                                  <td>    3.4619</td> <td>    1.064</td> <td>    3.254</td> <td> 0.001</td> <td>    1.377</td> <td>    5.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk-Transit-Walk</th>                                <td>   -0.3921</td> <td>    0.288</td> <td>   -1.360</td> <td> 0.174</td> <td>   -0.957</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Drive-Transit-Walk</th>                               <td>   -2.6220</td> <td>    0.303</td> <td>   -8.660</td> <td> 0.000</td> <td>   -3.215</td> <td>   -2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk-Transit-Drive</th>                               <td>   -2.9773</td> <td>    0.306</td> <td>   -9.725</td> <td> 0.000</td> <td>   -3.577</td> <td>   -2.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Walk</th>                                             <td>    1.5541</td> <td>    0.305</td> <td>    5.101</td> <td> 0.000</td> <td>    0.957</td> <td>    2.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC Bike</th>                                             <td>   -1.1059</td> <td>    0.305</td> <td>   -3.628</td> <td> 0.000</td> <td>   -1.703</td> <td>   -0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Time, units:min (All Auto Modes)</th>              <td>   -0.0760</td> <td>    0.006</td> <td>  -13.728</td> <td> 0.000</td> <td>   -0.087</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Time, units:min (All Transit Modes)</th>           <td>   -0.0274</td> <td>    0.002</td> <td>  -12.768</td> <td> 0.000</td> <td>   -0.032</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost, units:$ (All Transit Modes)</th>             <td>   -0.1273</td> <td>    0.037</td> <td>   -3.472</td> <td> 0.001</td> <td>   -0.199</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (Drive Alone)</th>   <td>   -5.0613</td> <td>    1.377</td> <td>   -3.675</td> <td> 0.000</td> <td>   -7.760</td> <td>   -2.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (SharedRide-2)</th>  <td>  -20.3194</td> <td>    4.548</td> <td>   -4.467</td> <td> 0.000</td> <td>  -29.234</td> <td>  -11.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Cost per Distance, units:$/mi (SharedRide-3+)</th> <td>  -90.9224</td> <td>   14.748</td> <td>   -6.165</td> <td> 0.000</td> <td> -119.829</td> <td>  -62.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Autos per licensed drivers (All Auto Modes)</th>          <td>    1.2134</td> <td>    0.129</td> <td>    9.408</td> <td> 0.000</td> <td>    0.961</td> <td>    1.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Distance, units:mi (Walk)</th>                     <td>   -1.0272</td> <td>    0.050</td> <td>  -20.437</td> <td> 0.000</td> <td>   -1.126</td> <td>   -0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Travel Distance, units:mi (Bike)</th>                     <td>   -0.2873</td> <td>    0.024</td> <td>  -11.896</td> <td> 0.000</td> <td>   -0.335</td> <td>   -0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cross-Bay Tour (Shared Ride 2 & 3+)</th>                  <td>    0.9280</td> <td>    0.327</td> <td>    2.839</td> <td> 0.005</td> <td>    0.287</td> <td>    1.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Household Size (Shared Ride 2 & 3+)</th>                  <td>    0.1136</td> <td>    0.045</td> <td>    2.523</td> <td> 0.012</td> <td>    0.025</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Kids in Household (Shared Ride 2 & 3+)</th>     <td>    0.6868</td> <td>    0.054</td> <td>   12.820</td> <td> 0.000</td> <td>    0.582</td> <td>    0.792</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     Multinomial Logit Model Regression Results                    \n",
       "===================================================================================\n",
       "Dep. Variable:                      choice   No. Observations:                4,004\n",
       "Model:             Multinomial Logit Model   Df Residuals:                    3,985\n",
       "Method:                                MLE   Df Model:                           19\n",
       "Date:                     Sun, 08 Mar 2020   Pseudo R-squ.:                   0.332\n",
       "Time:                             14:02:51   Pseudo R-bar-squ.:               0.330\n",
       "AIC:                            10,184.855   Log-Likelihood:             -5,073.428\n",
       "BIC:                            10,304.461   LL-Null:                    -7,599.702\n",
       "========================================================================================================================\n",
       "                                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------\n",
       "ASC Shared Ride: 2                                      -1.0097      0.486     -2.079      0.038      -1.962      -0.058\n",
       "ASC Shared Ride: 3+                                      3.4619      1.064      3.254      0.001       1.377       5.547\n",
       "ASC Walk-Transit-Walk                                   -0.3921      0.288     -1.360      0.174      -0.957       0.173\n",
       "ASC Drive-Transit-Walk                                  -2.6220      0.303     -8.660      0.000      -3.215      -2.029\n",
       "ASC Walk-Transit-Drive                                  -2.9773      0.306     -9.725      0.000      -3.577      -2.377\n",
       "ASC Walk                                                 1.5541      0.305      5.101      0.000       0.957       2.151\n",
       "ASC Bike                                                -1.1059      0.305     -3.628      0.000      -1.703      -0.508\n",
       "Travel Time, units:min (All Auto Modes)                 -0.0760      0.006    -13.728      0.000      -0.087      -0.065\n",
       "Travel Time, units:min (All Transit Modes)              -0.0274      0.002    -12.768      0.000      -0.032      -0.023\n",
       "Travel Cost, units:$ (All Transit Modes)                -0.1273      0.037     -3.472      0.001      -0.199      -0.055\n",
       "Travel Cost per Distance, units:$/mi (Drive Alone)      -5.0613      1.377     -3.675      0.000      -7.760      -2.362\n",
       "Travel Cost per Distance, units:$/mi (SharedRide-2)    -20.3194      4.548     -4.467      0.000     -29.234     -11.405\n",
       "Travel Cost per Distance, units:$/mi (SharedRide-3+)   -90.9224     14.748     -6.165      0.000    -119.829     -62.016\n",
       "Autos per licensed drivers (All Auto Modes)              1.2134      0.129      9.408      0.000       0.961       1.466\n",
       "Travel Distance, units:mi (Walk)                        -1.0272      0.050    -20.437      0.000      -1.126      -0.929\n",
       "Travel Distance, units:mi (Bike)                        -0.2873      0.024    -11.896      0.000      -0.335      -0.240\n",
       "Cross-Bay Tour (Shared Ride 2 & 3+)                      0.9280      0.327      2.839      0.005       0.287       1.569\n",
       "Household Size (Shared Ride 2 & 3+)                      0.1136      0.045      2.523      0.012       0.025       0.202\n",
       "Number of Kids in Household (Shared Ride 2 & 3+)         0.6868      0.054     12.820      0.000       0.582       0.792\n",
       "========================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the basic MNL model, using the hessian and newton-conjugate gradient\n",
    "mnl_model = pl.create_choice_model(data=bike_data,\n",
    "                                   alt_id_col=\"mode_id\",\n",
    "                                   obs_id_col=\"observation_id\",\n",
    "                                   choice_col=\"choice\",\n",
    "                                   specification=mnl_specification,\n",
    "                                   model_type=\"MNL\",\n",
    "                                   names=mnl_names)\n",
    "\n",
    "num_vars = len(reduce(lambda x, y: x + y, mnl_names.values()))\n",
    "# Note newton-cg used to ensure convergence to a point where gradient \n",
    "# is essentially zero for all dimensions. \n",
    "mnl_model.fit_mle(np.zeros(num_vars),\n",
    "                  method=\"BFGS\")\n",
    "\n",
    "# Look at the estimation results\n",
    "mnl_model.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store beta coefficients\n",
    "mnl_parameters = mnl_model.params\n",
    "\n",
    "# Store T-values\n",
    "mnl_tvalues = mnl_model.tvalues\n",
    "\n",
    "# Store P-values\n",
    "mnl_pvalues = mnl_model.pvalues\n",
    "\n",
    "# Store confidennce intervals for each of the model coefficients\n",
    "mnl_conf_int = mnl_model.conf_int(alpha=0.05, return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data from Long to Wide before simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model variables of interest are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['total_travel_time',\n",
       " 'total_travel_cost',\n",
       " 'cost_per_distance',\n",
       " 'cars_per_licensed_drivers',\n",
       " 'total_travel_distance',\n",
       " 'cross_bay',\n",
       " 'household_size',\n",
       " 'num_kids',\n",
       " 'mode_id',\n",
       " 'observation_id',\n",
       " 'choice']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable list for subset of long data\n",
    "alt_id_col = \"mode_id\"\n",
    "\n",
    "obs_id_col = \"observation_id\"\n",
    "\n",
    "choice_col = \"choice\"\n",
    "\n",
    "# Store of columns relevant to the data to be simulated\n",
    "model_variables = list(mnl_model.specification.keys())\n",
    "model_variables.remove('intercept')\n",
    "model_variables.extend([alt_id_col, obs_id_col, choice_col])\n",
    "print('The model variables of interest are:')\n",
    "model_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data subset\n",
    "subset_bike_data = bike_data[model_variables].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the needed variables for the conversion\n",
    "individual_specific_variables = ['num_kids','household_size','cars_per_licensed_drivers','cross_bay']\n",
    "\n",
    "alternative_specific_variables = ['total_travel_time','total_travel_distance']\n",
    "\n",
    "subset_specific_variables = {'total_travel_cost': [1,2,3],\n",
    "                             'cost_per_distance': [1,2,3]}\n",
    "\n",
    "alternative_name_dict = {1: 'drive_alone',\n",
    "                         2: 'shared_2',\n",
    "                         3: 'shared_3p',\n",
    "                         4: 'wtw',\n",
    "                         5: 'dtw',\n",
    "                         6: 'wtd',\n",
    "                         7: 'walk',\n",
    "                         8: 'bike'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_id</th>\n",
       "      <th>choice</th>\n",
       "      <th>availability_drive_alone</th>\n",
       "      <th>availability_shared_2</th>\n",
       "      <th>availability_shared_3p</th>\n",
       "      <th>availability_wtw</th>\n",
       "      <th>availability_dtw</th>\n",
       "      <th>availability_wtd</th>\n",
       "      <th>availability_walk</th>\n",
       "      <th>availability_bike</th>\n",
       "      <th>...</th>\n",
       "      <th>total_travel_distance_dtw</th>\n",
       "      <th>total_travel_distance_wtd</th>\n",
       "      <th>total_travel_distance_walk</th>\n",
       "      <th>total_travel_distance_bike</th>\n",
       "      <th>total_travel_cost_drive_alone</th>\n",
       "      <th>total_travel_cost_shared_2</th>\n",
       "      <th>total_travel_cost_shared_3p</th>\n",
       "      <th>cost_per_distance_drive_alone</th>\n",
       "      <th>cost_per_distance_shared_2</th>\n",
       "      <th>cost_per_distance_shared_3p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.11</td>\n",
       "      <td>29.11</td>\n",
       "      <td>5.7140</td>\n",
       "      <td>3.2651</td>\n",
       "      <td>2.2856</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>0.105598</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.80</td>\n",
       "      <td>24.80</td>\n",
       "      <td>4.4519</td>\n",
       "      <td>2.5439</td>\n",
       "      <td>1.7807</td>\n",
       "      <td>0.184803</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.073919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.184802</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.073912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.64</td>\n",
       "      <td>40.64</td>\n",
       "      <td>5.9782</td>\n",
       "      <td>3.4162</td>\n",
       "      <td>2.3913</td>\n",
       "      <td>0.184798</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   observation_id  choice  availability_drive_alone  availability_shared_2  \\\n",
       "0             1.0     2.0                         1                      1   \n",
       "1             2.0     2.0                         1                      1   \n",
       "2             3.0     1.0                         1                      1   \n",
       "3             4.0     1.0                         1                      1   \n",
       "4             5.0     1.0                         1                      1   \n",
       "\n",
       "   availability_shared_3p  availability_wtw  availability_dtw  \\\n",
       "0                       1                 1                 1   \n",
       "1                       1                 1                 1   \n",
       "2                       1                 1                 1   \n",
       "3                       1                 1                 1   \n",
       "4                       1                 0                 1   \n",
       "\n",
       "   availability_wtd  availability_walk  availability_bike  ...  \\\n",
       "0                 1                  1                  1  ...   \n",
       "1                 1                  1                  1  ...   \n",
       "2                 1                  1                  1  ...   \n",
       "3                 1                  1                  1  ...   \n",
       "4                 0                  1                  1  ...   \n",
       "\n",
       "   total_travel_distance_dtw  total_travel_distance_wtd  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        NaN   \n",
       "\n",
       "   total_travel_distance_walk  total_travel_distance_bike  \\\n",
       "0                       29.11                       29.11   \n",
       "1                       24.80                       24.80   \n",
       "2                        8.38                        8.38   \n",
       "3                        8.38                        8.38   \n",
       "4                       40.64                       40.64   \n",
       "\n",
       "   total_travel_cost_drive_alone  total_travel_cost_shared_2  \\\n",
       "0                         5.7140                      3.2651   \n",
       "1                         4.4519                      2.5439   \n",
       "2                         1.6817                      0.9609   \n",
       "3                         1.6817                      0.9609   \n",
       "4                         5.9782                      3.4162   \n",
       "\n",
       "   total_travel_cost_shared_3p  cost_per_distance_drive_alone  \\\n",
       "0                       2.2856                       0.184799   \n",
       "1                       1.7807                       0.184803   \n",
       "2                       0.6726                       0.184802   \n",
       "3                       0.6726                       0.184802   \n",
       "4                       2.3913                       0.184798   \n",
       "\n",
       "   cost_per_distance_shared_2  cost_per_distance_shared_3p  \n",
       "0                    0.105598                     0.073920  \n",
       "1                    0.105600                     0.073919  \n",
       "2                    0.105593                     0.073912  \n",
       "3                    0.105593                     0.073912  \n",
       "4                    0.105601                     0.073920  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data from long to wide\n",
    "bike_data_wide = pl.convert_long_to_wide(long_data=subset_bike_data,\n",
    "                                         ind_vars=individual_specific_variables,\n",
    "                                         alt_specific_vars=alternative_specific_variables,\n",
    "                                         subset_specific_vars=subset_specific_variables,\n",
    "                                         obs_id_col=obs_id_col,\n",
    "                                         alt_id_col=alt_id_col,\n",
    "                                         choice_col=choice_col,\n",
    "                                         alt_name_dict=alternative_name_dict,)\n",
    "bike_data_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to decide how we will simulate data when we have unavailable values. TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial the FitDistribution object\n",
    "bike_data_fitter = FitDistribution(data=bike_data_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nature of each variables whether discrete/categorical or continuous\n",
    "variable_type = {'intercept':'categorical',\n",
    "                'total_travel_time':'continuous',\n",
    "                'total_travel_cost':'continuous',\n",
    "                'cost_per_distance':'continuous',\n",
    "                'cars_per_licensed_drivers':'continuous',\n",
    "                'total_travel_distance':'continuous',\n",
    "                'cross_bay':'categorical',\n",
    "                'household_size':'categorical',\n",
    "                'num_kids':'categorical'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = bike_data_fitter.FindDfDist(var_types=variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate Model on Simulated Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
