{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this notebook is to demonstrate prior and predictive checks of one's causal graphical model.\n",
    "\n",
    "The prior checks are to be used as part of one's falsification efforts before estimating the posterior distribution of one's unknown model parameters. If one's causal model contains latent variables, then such prior checks are expected to be extremely valuable. They are expected to indicate when one's model is likely to poorly fit one's data. This information can be used to avoid a potentially lengthy model estimation process. These checks will likely be implemented with very liberal thresholds for deciding that a model is not even worth beign estimated.\n",
    "\n",
    "The posterior predictive checks are to really ensure that the observed data is well fit by the assumptions of one's causal model.\n",
    "\n",
    "# Logical steps\n",
    "0. Determine the test statistic to be computed.\n",
    "1. Require as inputs:\n",
    "   1. predictive samples of all model variables (latent and observed),\n",
    "   2. function to compute the desired test statistic given a sample from the causal graph,\n",
    "   3. the observed data.\n",
    "   4. function to plot the distribution of the simulated test statistic and the value/distribution of the observed test statistic.\n",
    "2. For each predictive sample,\n",
    "   1. Compute the value of the simulated and observed test statistic (assuming the observed test statistic also depends on the simulated values. If not, simply store the value of the observed test statistic and do not recompute it.)\n",
    "   2. Store the simulated and observed test statistics.\n",
    "3. Visualize the distribution of the simulated and observed test statistics.\n",
    "4. Produce a scalar summary of the distribution of simulated test statistics if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare hyperparameters for testing\n",
    "MIN_SAMPLES_LEAF = 40\n",
    "NUM_PERMUTATIONS = 100\n",
    "\n",
    "# Declare the columns to be used for testing\n",
    "x1_col = 'total_travel_time'\n",
    "x2_col = 'total_travel_cost'\n",
    "mode_id_col = 'mode_id'\n",
    "\n",
    "# Set the colors for plotting\n",
    "ORIG_COLOR = '#045a8d'\n",
    "SIMULATED_COLOR = '#a6bddb'\n",
    "\n",
    "# Declare paths to data\n",
    "DATA_PATH =\\\n",
    "    '../../data/raw/spring_2016_all_bay_area_long_format_plus_cross_bay_col.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pdb import set_trace as bp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.insert(0, '../../src/')\n",
    "import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_regressor(x_2d, y, seed=None):\n",
    "    # regressor_kwargs =\\\t    regressor = LinearRegression()\n",
    "    #     {'min_samples_leaf': MIN_SAMPLES_LEAF,\n",
    "    #      'max_samples': 0.8}\n",
    "    # if seed is not None:\n",
    "    #     regressor_kwargs['random_state'] = seed + 10\n",
    "    # regressor =\\\n",
    "    #     RandomForestRegressor(**regressor_kwargs)\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_2d, y)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def computed_vs_obs_r2(x1_array,\n",
    "                       x2_array,\n",
    "                       z_array,\n",
    "                       seed,\n",
    "                       progress=True):\n",
    "    # Combine the various predictors\n",
    "    combined_obs_predictors =\\\n",
    "        np.concatenate((x2_array[:, None], z_array[:, None]), axis=1)\n",
    "\n",
    "    # Determine the number of rows being plotted\n",
    "    num_rows = x1_array.shape[0]\n",
    "\n",
    "    # Create a regressor to be used to compute the conditional expectations\n",
    "    regressor = _make_regressor(combined_obs_predictors, x1_array, seed)\n",
    "\n",
    "    # Get the observed expectations\n",
    "    obs_expectation = regressor.predict(combined_obs_predictors)\n",
    "    obs_r2 = r2_score(x1_array, obs_expectation)\n",
    "\n",
    "    # Initialize arrays to store the permuted expectations and r2's\n",
    "    permuted_expectations = np.empty((num_rows, NUM_PERMUTATIONS))\n",
    "    permuted_r2 = np.empty(NUM_PERMUTATIONS, dtype=float)\n",
    "\n",
    "    # Get the permuted expectations\n",
    "    shuffled_index_array = np.arange(num_rows)\n",
    "\n",
    "    iterable = range(NUM_PERMUTATIONS)\n",
    "    if progress:\n",
    "        iterable = tqdm(iterable)\n",
    "\n",
    "    for i in iterable:\n",
    "        # Shuffle the index array\n",
    "        np.random.shuffle(shuffled_index_array)\n",
    "        # Get the new set of permuted X_2 values\n",
    "        current_x2 = x2_array[shuffled_index_array]\n",
    "        # Get the current combined predictors\n",
    "        current_predictors =\\\n",
    "            np.concatenate((current_x2[:, None], obs_z[:, None]), axis=1)\n",
    "        # Fit a new model and store the current expectation\n",
    "        current_regressor =\\\n",
    "            _make_regressor(current_predictors, x1_array, seed)\n",
    "        permuted_expectations[:, i] =\\\n",
    "            current_regressor.predict(current_predictors)\n",
    "        permuted_r2[i] = r2_score(x1_array, permuted_expectations[:, i])\n",
    "    return obs_r2, permuted_r2\n",
    "\n",
    "\n",
    "def compute_pvalue(obs_r2, permuted_r2):\n",
    "    return (obs_r2 < permuted_r2).mean()\n",
    "\n",
    "\n",
    "def compute_predictive_independence_test_values(samples, obs_sample, seed):\n",
    "    \"\"\"\n",
    "    test_values = p-values of conditional independence test\n",
    "    \"\"\"\n",
    "    # Determine the number of samples in order to create an iterable for\n",
    "    # getting and storing test samples\n",
    "    if len(samples.shape != 3):\n",
    "        msg = '`samples` should have shape (num_rows, 3, num_samples).'\n",
    "        raise ValueError(msg)\n",
    "    num_samples = samples.shape[-1]\n",
    "\n",
    "    # Initialize a container for the p-values of the sampled and observed data\n",
    "    sampled_pvals = np.empty((num_samples,), dtype=float)\n",
    "    obs_pvals = np.empty((num_samples,), dtype=float)\n",
    "\n",
    "    # Create the iterable to be looped over to compute test values\n",
    "    iterable = range(NUM_PERMUTATIONS)\n",
    "    if progress:\n",
    "        iterable = tqdm(iterable)\n",
    "\n",
    "    # Populate the arrays of test statistics\n",
    "    for i in iterable:\n",
    "        # Get the data to be used to calculate this set of p-values\n",
    "        current_sim_sample = samples[:, :, i]\n",
    "        current_sim_z = current_sim_sample[:, -1]\n",
    "        current_augmented_obs = np.concatenate((obs_samples, current_sim_z))\n",
    "\n",
    "        # Package the arguments to compute the predictive r2 values\n",
    "        sim_args =\\\n",
    "            (current_sim_sample[:, 0],\n",
    "             current_sim_sample[:, 1],\n",
    "             current_sim_z,\n",
    "             seed,\n",
    "             False\n",
    "            )\n",
    "\n",
    "        augmented_obs_args =\\\n",
    "            (current_augmented_obs[:, 0],\n",
    "             current_augmented_obs[:, 1],\n",
    "             current_augmented_obs[:, 2],\n",
    "             seed,\n",
    "             False\n",
    "            )\n",
    "\n",
    "        # Compute and store the p-values of the conditional independence\n",
    "        # test for the current simulated and augmented dataset\n",
    "        sampled_pvals[i] =\\\n",
    "            compute_pvalue(computed_vs_obs_r2(*sim_args))\n",
    "\n",
    "        obs_pvals[i] =\\\n",
    "            compute_pvalue(computed_vs_obs_r2(*augmented_obs_args))\n",
    "    return sampled_pvals, obs_pvals\n",
    "\n",
    "\n",
    "def visualize_predictive_cit_results(\n",
    "        sampled_pvals,\n",
    "        obs_pvals,\n",
    "        verbose=True,\n",
    "        show=True,\n",
    "        close=False):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    overall_p_value = (obs_pvals < sampled_pvals).mean()\n",
    "\n",
    "    if verbose:\n",
    "        msg =\\\n",
    "            'The p-value of the predictive, permutation C.I.T. is {:.2f}.'\n",
    "        print(msg.format(overall_p_value))\n",
    "\n",
    "    sbn.kdeplot(\n",
    "        sampled_pvals, ax=ax, color=SIMULATED_COLOR, label='Simulated')\n",
    "    sbn.kdeplot(\n",
    "        obs_pvals, ax=ax, color=ORIG_COLOR, label='Observed')\n",
    "\n",
    "    ax.set_xlabel('Permutation P-value', fontsize=13)\n",
    "    ax.set_ylabel(\n",
    "        'Density', fontdict={'fontsize':13, 'rotation':0}, labelpad=40)\n",
    "    ax.legend(loc='best')\n",
    "    sbn.despine()\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if close:\n",
    "        plt.close(fig=fig)\n",
    "    return overall_p_value\n",
    "\n",
    "\n",
    "def perform_visual_predictive_cit_test(\n",
    "        samples,\n",
    "        obs_sample\n",
    "        seed=1038,\n",
    "        verbose=True,\n",
    "        show=True,\n",
    "        close=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : 3D ndarray of shape (num_rows, 3, num_samples).\n",
    "        Columns should contain, in order, simulated x1, x2, z.\n",
    "    obs_sample : 2D ndarray of shape (num_rows, 2)\n",
    "        Columns should contain, in order, observed x1, observed x2.\n",
    "    \"\"\"\n",
    "    # Set a random seed for reproducibility\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Compute the observed and sampled pvalues\n",
    "    sampled_pvals, obs_pvals =\\\n",
    "        compute_predictive_independence_test_values(\n",
    "            samples, obs_sample, seed)\n",
    "\n",
    "    # Visualize the results of the predictive permutation CIT test\n",
    "    overall_p_value =\\\n",
    "        visualize_predictive_cit_results(\n",
    "            sampled_pvals, obs_pvals, verbose=verbose, show=show, close=close)\n",
    "    return p_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values to be used for testing\n",
    "filter_array = (df[mode_id_col] == 1).values\n",
    "obs_x1 = df[x1_col].values[filter_array]\n",
    "obs_x2 = df[x2_col].values[filter_array]\n",
    "obs_sample = np.concatenate((obs_x1, obs_x2), axis=1)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
