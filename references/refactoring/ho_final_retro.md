# Final Retrospective


## Overall thoughts
The project was a great learning experience. 
I appreciated our consistency, and the ability to stay on track. 
The discussions were helpful, and I felt like they were very constructive. 
The atmosphere for the work was conducive to good work: no toxicity, and everyone accepts feedback. 

To me, the most important part in any evaluation is to point out what can be done better, so that we can learn from this exercise and hopefully address them in the future. 
So, if what I list below seems more negative than positive, it's only because I believe we already have a good grasp on what we did well. 


## What went well. 
- Consistency with check-ins.
- Proactiveness when communicating delays, other commitments, and hiccups. 
- Good and productive discussions that resulted in actionable items most of the time. 
- Organization and streamlining got better towards the end. (see below)

## What could/should be done better. 
- Understanding when organization and adhering to strict coding protocols is more of an inconvenience than help.
  - I often felt overwhelmed with trying to do things "right" from a github perspective, resulting in slowing down the work instead of speeding it up. 

- Understanding when it's important to have reproducible code, and when it's not. 
  - This is particularly relevant for part 1 with the simulations. 
  - The point we're making is simple, changing one variable and using the outcome model is different than changing all variables based on a causal graph.
  - When I suggested this idea, I didn't think it's groundbreaking, and the example we had is just illustrative. 
  - I actually had to re-illustrate this point for my quals using a different example. 
  - I didn't end up using any of our codes, as re-coding things from scratch was way simpler, especially that adapting things to another example is not straightforward. 

- When writing, our focus should be on illustrating a point, not illustrating a process. 
  - Also particularly relevant for part I. 
  - Listing how the simulation was done is not necessary, and I would argue that it's actually worse to include it than to skip it. 
  - These are details that seem to be there to show that a lot of work went here to illustrate a simple point: readers don't care about this. 

- We should keep our audience and publication outlet in mind while writing:
  - The discussion of more complicated cases, cyclic graphs, undirected graphs, etc., while useful and interesting, I believe is irrelevant to the readers of the HCM and to travel demand modelers in general. 

- We should have a clear discussion of contributions ahead of time, and discuss authorship and whatnot. 
  - I understand these conversations can be uncomfortable to have, especially among friends, but we need more clarity on this and to make sure we're all in the same page. We'll discuss more in the call. 
  